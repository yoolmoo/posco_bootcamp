{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 구성:Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# export_graphviz: 나무 구조 생성 및 저장 \n",
    "from sklearn.tree import export_graphviz\n",
    "# graphviz : 나무 구조 시각화  (.dot 확장자 파일 불러오기 등)\n",
    "import graphviz\n",
    "\n",
    "# 다른 방식(.dot -> .png 형식, 출력화면에 맞는)으로 Tree 출력\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "\n",
    "# 데이터 분할:train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 분류 Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 최적 모델, 파라미터 탐색\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 분류모델 평가 함수\n",
    "from sklearn.metrics import accuracy_score, f1_score \n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# graphviz 설치: 의사결정나무 결과 저장(.dot 등) 및 파일 불러오기/확인\n",
    "* download :url: https://graphviz.org/download/ (linux version 확인 필요)  (windows_XXXX_graphviz-install-XXX-winXX)\n",
    "* 파일 설치 및 윈도우 시스템/환경변수에 설치 경로 추가\n",
    "* graphviz module 설치 (anaconda prompt -> pip install graphviz)\n",
    "\n",
    "* manual:https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree 생성경로 지정\n",
    "import os\n",
    "# PATH 설정: graphviz를 설치 했다면, 설치 된 경로를 설정. 기본 경로는 아래 예제 참고(linux에서 설치된 경로 확인 및 변경 필요)\n",
    "# os.environ[\"PATH\"] += os.pathsep + \"C:/Program Files (x86)/Graphviz2.38/bin/\"\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:/Program Files/Graphviz/bin/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래프 옵션 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 한글폰트 적용:맑은 고딕\n",
    "matplotlib.rc(\"font\", family = \"Malgun Gothic\")\n",
    "# 그래프 (-) 기호 표시\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df_raw = pd.read_csv(\"D:/WORK/DATA/HMEQ.CSV\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 구조 확인\n",
    "print(\"Data 구조:\", df_raw.shape)\n",
    "print()\n",
    "print(\"변수 : \", df_raw.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인\n",
    "df_raw.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna: 결측치를 채우는 함수\n",
    "# JOB 변수의 결측치는 Other로 입력, inplace: fillna 함수 적용 후 ds_hmeq 데이터에 저장, False면 저장 안 함\n",
    "df_raw[\"JOB\"].fillna(\"Other\", inplace = True)\n",
    "\n",
    "# 숫자형 변수의 결측치는 해당 변수의 평균값 입력: ds_hmeq.mean() 각 변수별 평균 계산 후 결측치 대체\n",
    "df_raw.fillna(df_raw.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리 확인\n",
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 범주형 설명변수 더미 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_dummies: 데이터의 문자형 변수에 대한 더미변수 생성 \n",
    "df_raw_dummy = pd.get_dummies(df_raw)\n",
    "df_raw_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 분리/ 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리:설명변수, 목표변수 구분\n",
    "df_raw_x = df_raw_dummy.drop(\"BAD\", axis = 1, inplace = False)\n",
    "df_raw_y = df_raw_dummy[\"BAD\"] \n",
    "\n",
    "# 데이터 분할 train_test_split(X: 설명변수, Y: 목표변수, test_size = test 데이터 비율)\n",
    "df_train_x, df_test_x, df_train_y, df_test_y = train_test_split(\n",
    "    df_raw_x, df_raw_y, test_size = 0.3, random_state = 1234) \n",
    "\n",
    "print(\"분할 전 설명변수 데이터 :\", df_raw_x.shape)\n",
    "print(\"분할 후 설명변수 데이터 :Train\", df_train_x.shape, \"  Test\",df_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(df_raw.head(10))\n",
    "display(df_raw_x.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data 구조 확인\n",
    "print(\"Data 구조:\", df_raw_x.columns)\n",
    "print()\n",
    "print(\"변수 : \", df_train_x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @불균형 자료 사전 처리:over-, under-sampling-SMOTE\n",
    "\n",
    "class imblearn.over_sampling.SMOTE(*, sampling_strategy='auto', random_state=None, k_neighbors=5, n_jobs=None)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 샘플링 : Over-sampling 등\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표변수 빈도 확인\n",
    "print(df_raw.value_counts([\"BAD\"]),\"\\n\")\n",
    "print(\"BAD=1 비율  \", df_raw.value_counts(df_raw[\"BAD\"]==1)/len(df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 목표변수 산점도 확인\n",
    "plt.figure(figsize=(10,8))\n",
    "# 색깔 지정\n",
    "df_raw['color'] = np.where(df_raw[\"BAD\"]==1, \"red\", \"blue\")\n",
    "# plt.scatter(df_raw['LOAN'],df_raw['VALUE'],c=df_raw['BAD'], s=30, alpha=0.5)\n",
    "plt.scatter(df_raw['LOAN'],df_raw['VALUE'],c=df_raw['color'], s=30, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling 설정\n",
    "sm = SMOTE(sampling_strategy='auto', random_state=1234)\n",
    "\n",
    "# train데이터를 이용한 Over-sampling\n",
    "x_resampled, y_resampled = sm.fit_resample(df_train_x,df_train_y)\n",
    "\n",
    "# 결과 확인\n",
    "print('Over-Sampling 전:\\n',df_train_y.value_counts(),\"\\n\")\n",
    "print('Over-Sampling 후 Train X: {}'.format(x_resampled.shape))\n",
    "print('Over-Sampling 후 Train Y: {} \\n'.format(y_resampled.shape))\n",
    "\n",
    "print(\"Over-Sampling 후 '1':{}\".format(sum(y_resampled==1)))\n",
    "print(\"Over-Sampling 후 '0':{}\".format(sum(y_resampled==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 데이터 결합 및 산점도 확인\n",
    "df_resampled = pd.concat([x_resampled,y_resampled], axis=1)\n",
    "print(df_resampled.head())\n",
    "\n",
    "# 목표변수 산점도 확인:위와 다른 방식으로 색깔 구분\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(df_resampled['LOAN'],df_resampled['VALUE'],\n",
    "            c=df_resampled['BAD'],alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default option Moel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_uncust = DecisionTreeClassifier(random_state=1234 )\n",
    "tree_uncust.fit(df_train_x, df_train_y)\n",
    "\n",
    "# train 데이터 정확도\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree_uncust.score(df_train_x, df_train_y)))\n",
    "# test 데이터 정확도\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree_uncust.score(df_test_x, df_test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 실행옵션 확인\n",
    "print(tree_uncust.get_params().keys())\n",
    "print(tree_uncust.get_params().values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @max_depth(최대 깊이) 변화에 따른 모델 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# max_depth: 최대 깊이 변경.\n",
    "para_depth = [depth for depth in range(3, 12)]\n",
    "\n",
    "for v_max_depth in para_depth:\n",
    "    tree = DecisionTreeClassifier(max_depth = v_max_depth, random_state=1234)\n",
    "    tree.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(tree.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(tree.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_depth = pd.DataFrame()\n",
    "df_accuracy_depth[\"Depth\"] = para_depth\n",
    "df_accuracy_depth[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_depth[\"TestAccuracy\"] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정확도 확인\n",
    "df_accuracy_depth.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정확도 그래프 확인\n",
    "plt.plot(para_depth, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_depth, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 깊이(max_depth)에 따른 결과 확인\n",
    "* 깊이 = 4 : 간단한 모델..under-fitting, 정확도 미흡\n",
    "* 깊이 = 7 : 적절? ?\n",
    "* 깊이 = 10 : 복잡한 모델..over-fitting, Train~Test 정확도 차이 큼 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명 저장\n",
    "v_feature_name = df_train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# max_depth, 깊이: 얕은 모델\n",
    "tree_low = DecisionTreeClassifier(max_depth = 4, random_state=1234)\n",
    "tree_low.fit(df_train_x, df_train_y)\n",
    "\n",
    "# 트리 모델을 tree_low.dot 파일로 저장. (목표변수 레이블 지정(class_names):0-Good,1-Bad)\n",
    "export_graphviz(tree_low, out_file=\"tree_low.dot\", class_names = [\"Good\", \"Bad\"], \n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "\n",
    "# 트리 결과 시각화\n",
    "with open(\"tree_low.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 .dot 파일을 .png로 변환\n",
    "call(['dot', '-Tpng', 'tree_low.dot', '-o', 'tree_low.png', '-Gdpi=600'])\n",
    "# jupyter notebook에서 작업디렉토리에 있는 .png 직접 출력\n",
    "Image(filename = 'tree_low.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# max_depth 깊이:깊은 모델\n",
    "tree_high = DecisionTreeClassifier(max_depth = 7, random_state=1234)\n",
    "tree_high.fit(df_train_x, df_train_y)\n",
    "\n",
    "export_graphviz(tree_high, out_file=\"tree_high.dot\", class_names = [\"Good\", \"Bad\"],\n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "#                 feature_names = v_feature_name, impurity = True, filled = True, max_depth=5) # 표시 max_depth 지정 가능\n",
    "\n",
    "with open(\"tree_high.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 생성된 .dot 파일을 .png로 변환\n",
    "call(['dot', '-Tpng', 'tree_high.dot', '-o', 'tree_high.png', '-Gdpi=600'])\n",
    "# jupyter notebook에서 작업디렉토리에 있는 .png 직접 출력\n",
    "Image(filename = 'tree_high.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# max_depth(깊이) 지정 : 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @min_samples_split(분리노드의 최소 샘플 수) 조정에 따른 정확도 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참조:적정 크기를 어떻게 결정할  것인가?\n",
    "* Data의 자료 수 참조...1~5% ?(절대적인 기준은 없음!!)\n",
    "* 단, leaf 크기의 2배 수준 고려\n",
    "\n",
    "* min_samples_split 증가 -> 모델 정확도 감소 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참조:적정 자료 수 검토:Train Data 자료 수\n",
    "print(\"전체 자료 = \", df_train_x.shape[0],\"개\")\n",
    "print(\"전체 자료의 1% = \", df_train_x.shape[0] * 0.01,\"개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# min_samples_split: 분할하기 위한 노드의 최소 샘플 수 \n",
    "para_split = [n_split * 10 for n_split in range(2, 16)]\n",
    "\n",
    "for v_min_samples_split in para_split:\n",
    "    tree = DecisionTreeClassifier(min_samples_split = v_min_samples_split, max_depth=7, random_state=1234)\n",
    "    tree.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(tree.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(tree.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_split = pd.DataFrame()\n",
    "df_accuracy_split[\"MinSamplesSplit\"] = para_split\n",
    "df_accuracy_split[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_split[\"TestAccuracy\"] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정확도 확인\n",
    "df_accuracy_split.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 정확도를 그래프로 표현\n",
    "plt.plot(para_split, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_split, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### @해석 : \n",
    "▶ 분리 노드의 최소 자료 수 증가에 따라 모델의 정확도는 감소하며\n",
    "30에서 성능이 약간 저하되고 이후 큰 변화가 없음. 전체 자료수 및 파라미터 특징(max_XXX)을 고려하여 50 선택(전체 자료의 1% 수준)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 분리 노드의 최소 샘플 수(min_samples_split)에 따른 차이 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 분리 노드의 최소 자료 수:적은 모델\n",
    "tree_low = DecisionTreeClassifier(max_depth=7, min_samples_split=50, random_state=1234)\n",
    "tree_low.fit(df_train_x, df_train_y)\n",
    "\n",
    "export_graphviz(tree_low, out_file=\"tree_low.dot\", class_names = [\"Good\", \"Bad\"],\n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "\n",
    "with open(\"tree_low.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 .dot 파일을 .png로 변환\n",
    "call(['dot', '-Tpng', 'tree_low.dot', '-o', 'tree_low.png', '-Gdpi=600'])\n",
    "# jupyter notebook에서 작업디렉토리에 있는 .png 직접 출력\n",
    "Image(filename = 'tree_low.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 분리 노드의 최소 자료 수: 많은 모델\n",
    "tree_high = DecisionTreeClassifier(max_depth=7, min_samples_split=110, random_state=1234)\n",
    "tree_high.fit(df_train_x, df_train_y)\n",
    "\n",
    "export_graphviz(tree_high, out_file=\"tree_high.dot\", class_names = [\"Good\", \"Bad\"],\n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "\n",
    "with open(\"tree_high.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 생성된 .dot 파일을 .png로 변환\n",
    "call(['dot', '-Tpng', 'tree_high.dot', '-o', 'tree_high.png', '-Gdpi=600'])\n",
    "# jupyter notebook에서 작업디렉토리에 있는 .png 직접 출력\n",
    "Image(filename = 'tree_high.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# min_samples_split(분리노드의 최소 샘플 수) 지정 : 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @min_samples_leaf(잎사귀 노드의 샘플 수) 조정에 따른 정확도 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참조:적정 크기를 어떻게 결정할 것인가?\n",
    "* Data의 자료 수 참조...0.5~5% ?(절대적인 기준은 없음!!)\n",
    " \n",
    "* min_samples_leaf 증가 -> 모델 정확도 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# min_samples_leaf: 잎사귀 노드 최소 자료 수. \n",
    "para_leaf = [n_leaf * 2 for n_leaf in range(5,16)]\n",
    "\n",
    "for v_min_samples_leaf in para_leaf:\n",
    "    tree = DecisionTreeClassifier(min_samples_leaf = v_min_samples_leaf, min_samples_split=50, \\\n",
    "\t\tmax_depth=7, random_state=1234)\n",
    "    tree.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(tree.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(tree.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_leaf = pd.DataFrame()\n",
    "df_accuracy_leaf[\"MinSamplesLeaf\"] = para_leaf\n",
    "df_accuracy_leaf[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_leaf[\"TestAccuracy\"] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정확도 확인\n",
    "df_accuracy_leaf.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 모델 정확도 그래프 확인\n",
    "plt.plot(para_leaf, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_leaf, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### @해석 : 10 초과 ->모델 정확도가 급격히 감소됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 잎사귀 노드의 샘플 수(min_samples_leaf)에 따른 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 잎사귀의 최소 자료 수가 8인 모델\n",
    "tree_low = DecisionTreeClassifier(max_depth=7, min_samples_split=50, min_samples_leaf=14, random_state=1234)\n",
    "tree_low.fit(df_train_x, df_train_y)\n",
    "\n",
    "export_graphviz(tree_low, out_file=\" tree_low.dot\", class_names = [\"Good\", \"Bad\"],\n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "\n",
    "with open(\" tree_low.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 .dot 파일을 .png로 변환\n",
    "call(['dot', '-Tpng', 'tree_low.dot', '-o', 'tree_low.png', '-Gdpi=600'])\n",
    "# jupyter notebook에서 작업디렉토리에 있는 .png 직접 출력\n",
    "Image(filename = 'tree_low.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 잎사귀의 최소 자료 수가 10인 모델\n",
    "tree_high = DecisionTreeClassifier(max_depth=7, min_samples_split=50, min_samples_leaf=18, random_state=1234)\n",
    "tree_high.fit(df_train_x, df_train_y)\n",
    "\n",
    "export_graphviz(tree_high, out_file=\"tree_high.dot\", class_names = [\"Good\", \"Bad\"],\n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "\n",
    "with open(\"tree_high.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 .dot 파일을 .png로 변환\n",
    "call(['dot', '-Tpng', 'tree_high.dot', '-o', 'tree_high.png', '-Gdpi=600'])\n",
    "# jupyter notebook에서 작업디렉토리에 있는 .png 직접 출력\n",
    "Image(filename = 'tree_high.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### @해석 : 조건에 따라 일부 차이 확인 \n",
    "* 분리 자료 수 차이 -> 분리 기준 차이 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# min_samples_leaf(잎사귀 노드의 샘플 수) 지정 : 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 모델 선정 / 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 모델:분석가 판단에 따라 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree_final = DecisionTreeClassifier(max_depth=7, min_samples_split=50, min_samples_leaf=14, random_state=1234)\n",
    "tree_final.fit(df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tree_final.dot으로 결과 저장\n",
    "export_graphviz(tree_final, out_file=\"tree_final.dot\", class_names = [\"Good\", \"Bad\"],\n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "\n",
    "with open(\"tree_final.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 .dot 파일을 .png로 변환\n",
    "call(['dot', '-Tpng', 'tree_final.dot', '-o', 'tree_final.png', '-Gdpi=600'])\n",
    "# jupyter notebook에서 작업디렉토리에 있는 .png 직접 출력\n",
    "Image(filename = 'tree_final.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "y_pred = tree_final.predict(df_test_x)\n",
    "print(\"Test Accuracy: {0:.3f}\\n\".format(tree_final.score(df_test_x, df_test_y)))\n",
    "print(\"Test Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "\n",
    "# 목표변수의 빈도 불균형 : f1 score로 모델 평가 \n",
    "print(classification_report(df_test_y, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 설명변수 중요도\n",
    "* Importance는 상대적인 값\n",
    "* Importance = 0 -> 적용 모델의 가지 분리시 해당 변수가 사용되지 않았다는 의미->다른 모델 생성 시에는 변경될 수 있음!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.feature_importances_로 설명변수 중요도 확인 및 테이블로 저장\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = v_feature_name\n",
    "df_importance[\"Importance\"] = tree_final.feature_importances_\n",
    "\n",
    "# df_feature_importance의 테이블을 중요도별로 정렬\n",
    "df_importance.sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_importance.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 설명변수 중요도 그래프\n",
    "# sort_values : 중요도가 높은 변수를 상위에 그림. \n",
    "df_importance.sort_values(\"Importance\", ascending=True, inplace = True)\n",
    "coordinates = range(len(df_importance))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.barh(y = coordinates, width = df_importance[\"Importance\"])\n",
    "plt.yticks(coordinates, df_importance[\"Feature\"])\n",
    "plt.xlabel(\"설명변수 중요도\")\n",
    "plt.ylabel(\"설명변수\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 분리기준 변경 및 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree_final2 = DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_split=50, min_samples_leaf=14, random_state=1234)\n",
    "tree_final2.fit(df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tree_final.dot으로 결과 저장\n",
    "export_graphviz(tree_final2, out_file=\"tree_final2.dot\", class_names = [\"Good\", \"Bad\"],\n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "\n",
    "with open(\"tree_final2.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 .dot 파일을 .png로 변환\n",
    "call(['dot', '-Tpng', 'tree_final2.dot', '-o', 'tree_final2.png', '-Gdpi=600'])\n",
    "# jupyter notebook에서 작업디렉토리에 있는 .png 직접 출력\n",
    "Image(filename = 'tree_final2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "y_pred = tree_final.predict(df_test_x)\n",
    "print(\"Accuracy: {0:.3f}\\n\".format(tree_final.score(df_test_x, df_test_y)))\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "\n",
    "# 목표변수의 빈도 불균형 : f1 score로 모델 평가 \n",
    "print(classification_report(df_test_y, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 설명변수 중요도\n",
    "* Importance는 상대적인 값\n",
    "* Importance = 0 -> 적용 모델의 가지 분리시 해당 변수가 사용되지 않았다는 의미->다른 모델 생성 시에는 변경될 수 있음!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.feature_importances_로 설명변수 중요도 확인 및 테이블로 저장\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = v_feature_name\n",
    "df_importance[\"Importance\"] = tree_final.feature_importances_\n",
    "\n",
    "# df_feature_importance의 테이블을 중요도별로 정렬\n",
    "df_importance.sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_importance.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @추가연습:Over-sampling Data이용한 모델링 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over-Sampling 데이터 분할-> 모델 비교\n",
    "\n",
    "* SMOTE Over-Sampling에 따라 선택되는 데이터가 다를 수 있어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 데이터 분할 train_test_split(X: 설명변수, Y: 목표변수, test_size = test 데이터 비율)\n",
    "df_train_x_over, df_test_x_over, df_train_y_over, df_test_y_over = train_test_split(\n",
    "    x_resampled, y_resampled, test_size = 0.3, stratify=y_resampled, random_state = 1234) \n",
    "\n",
    "print(\"분할 전 데이터 현황... 설명:\", x_resampled.shape, \"  목표:\", y_resampled.shape)\n",
    "print(\"분할 후 설명변수 현황...Train:\", df_train_x_over.shape, \" Test:\", df_test_x_over.shape)\n",
    "print(\"분할 후 목표변수 현황...Train:\", df_train_y_over.value_counts(), \" Test:\", df_test_y_over.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 최종 모델의 hyper-parameter 이용: 원칙은 하이퍼 파라미터 튜닝 필요\n",
    "tree_final_over = DecisionTreeClassifier(max_depth=7, min_samples_split=50, min_samples_leaf=14, random_state=1234)\n",
    "\n",
    "# Over-sampling Data 지정\n",
    "tree_final_over.fit(df_train_x_over, df_train_y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tree_final.dot으로 결과 저장\n",
    "export_graphviz(tree_final_over, out_file=\"tree_final_over.dot\", class_names = [\"Good\", \"Bad\"],\n",
    "                feature_names = v_feature_name, impurity = True, filled = True)\n",
    "\n",
    "with open(\"tree_final_over.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...다른 방식의 Tree 시각화(이미지가 큰 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 생성된 .dot 파일을 .png로 변환\n",
    "call(['dot', '-Tpng', 'tree_final_over.dot', '-o', 'tree_final_over.png', '-Gdpi=600'])\n",
    "\n",
    "# jupyter notebook에서 작업디렉토리에 있는 .png 직접 출력\n",
    "Image(filename = 'tree_final_over.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 평가\n",
    "y_pred_over = tree_final_over.predict(df_test_x_over)\n",
    "print(\"Test Accuracy: {0:.3f}\\n\".format(tree_final_over.score(df_test_x_over, df_test_y_over)))\n",
    "print(\"Test Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y_over, y_pred_over)))\n",
    "\n",
    "# 목표변수의 빈도 불균형 : f1 score로 모델 평가 \n",
    "print(classification_report(df_test_y_over, y_pred_over, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.feature_importances_로 설명변수 중요도 확인 및 테이블로 저장\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = v_feature_name\n",
    "df_importance[\"Importance\"] = tree_final_over.feature_importances_\n",
    "\n",
    "# df_feature_importance의 테이블을 중요도별로 정렬\n",
    "df_importance.sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_importance.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 설명변수 중요도 그래프\n",
    "# sort_values : 중요도가 높은 변수를 상위에 그림. \n",
    "df_importance.sort_values(\"Importance\", ascending=True, inplace = True)\n",
    "coordinates = range(len(df_importance))\n",
    "plt.barh(y = coordinates, width = df_importance[\"Importance\"])\n",
    "plt.yticks(coordinates, df_importance[\"Feature\"])\n",
    "plt.xlabel(\"설명변수 중요도\")\n",
    "plt.ylabel(\"설명변수\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "* Tree 모델의 hyper-parameter의 최적값 탐색\n",
    "* grid(값의 격자) 방식으로 값을 변경/조합하면서 모델의 성능 비교\n",
    "* 반복 모델 생성시 CV(cross-validation) 방식으로 data 선택 -> 개별 모델과 최적값이 다를 수 있음  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "estimator = DecisionTreeClassifier()\n",
    "# 구하고자 하는 parameter와 범위\n",
    "param_grid = {\"max_depth\": para_depth, \"min_samples_split\": para_split,\n",
    "              \"min_samples_leaf\": para_leaf}\n",
    "# 정확도가 높은 최적 parameter 찾기\n",
    "grid_dt = GridSearchCV(estimator, param_grid, scoring=\"accuracy\", n_jobs = -1)\n",
    "grid_dt.fit(df_train_x, df_train_y)\n",
    "\n",
    "print(\"best estimator model: \\n{}\".format(grid_dt.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(grid_dt.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(grid_dt.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### @해석 : 선정된 hyper-parameter가 타당(?) 하지 않을 수 있음\n",
    "\n",
    "* 분석가 모델 조건 : \n",
    "        class_weight=None, criterion='gini', max_depth=4,\n",
    "        max_features=None, max_leaf_nodes=None,\n",
    "        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "        min_samples_leaf=8, min_samples_split=20,\n",
    "        min_weight_fraction_leaf=0.0, presort=False, random_state=1234,\n",
    "        splitter='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of 의사결정나무"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
