{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 구성:Series, DataFrame\n",
    "import pandas as pd\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 데이터 scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 데이터 분할:train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 분류 Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 분류 Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 분류 Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# 분류 NN (MLPClassifier)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 모델 성능 평가: Precision, Recall, F1 Score, ROC Curve, AUC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Check the Frequency of Variable\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래프 옵션 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 한글폰트 적용:맑은 고딕\n",
    "matplotlib.rc(\"font\", family = \"Malgun Gothic\")\n",
    "# 그래프 (-) 기호 표시\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"D:/WORK/DATA/HMEQ.CSV\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 구조 확인\n",
    "print(\"Data 구조:\", df_raw.shape)\n",
    "print()\n",
    "print(\"변수 : \", df_raw.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  교재에 없음:부연 설명-범주형 변수의 수준(level)별 빈도수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 범주형 변수 list 생성\n",
    "#list_var_char = df_raw.select_dtypes(include='object').columns  # list가 아닌 변수 정보 추출\n",
    "\n",
    "list_var_char = list(df_raw.select_dtypes(include='object').columns)\n",
    "# list에서 특정값(변수) 제거:remove. 값 입력\n",
    "#list_var_char.remove(\"JOB\")\n",
    "# list에서 특정값(변수) 제거:del. 값의 index 입력\n",
    "#del list_var_char[0]\n",
    "\n",
    "# list에서 특정값(변수) 추가:append. 값 입력\n",
    "#list_var_char.append(\"BAD\")\n",
    "# list에서 특정값(변수) 추가:insert. index & 값 입력\n",
    "list_var_char.insert(0,\"BAD\")\n",
    "\n",
    "# list에 저장된 변수의 수준(level)별 빈도수 산출\n",
    "for v_var in list_var_char:\n",
    "    print(\"변수: \", v_var, \"Level = \",Counter(df_raw[v_var]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "\n",
    "1. 결측치 처리:모든 기법\n",
    "2. 데이터 분리(목표변수 vs. 설명변수):모든 기계학습 기법. 회귀분석은 분리 불필요\n",
    "3. 전처리 기준 \n",
    "    * 목표변수:전처리 처리 대상 아님\n",
    "    * 연속형 설명변수 scaling 적용:거리 기반 기법(SVM, NN, KNN, 군집분석, 주성분분석), 표준화 회귀계수(다중/로지스틱 회귀)\n",
    "    * 범주형 설명변수 duumy 변환:모든 기계학습 기법(DT, RF, GB, SVM, NN, KNN). 단, 회귀분석은 \"C(변수)\"로 처리\n",
    "4. 설명변수 결합\n",
    "5. 데이터 분할(Train vs. Test):모든 기법. 모델의 일반화, 과적합 방지 목적\n",
    "\n",
    "* 전처리 순서는 변경될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 변수별 결측치 현황 확인\n",
    "print(df_raw.isnull().sum(axis = 0))\n",
    "\n",
    "# fillna: 결측치를 채우는 함수\n",
    "# JOB 변수의 결측치는 Other로 입력, inplace: fillna 함수 적용 후 df_ raw 데이터에 저장, False면 저장 안 함\n",
    "df_raw[\"JOB\"].fillna(\"Other\", inplace = True)\n",
    "# 숫자형 변수의 결측치는 해당 변수의 평균값 입력: df_raw.mean() 각 변수별 평균 계산 후 결측치 대체\n",
    "df_raw.fillna(df_raw.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결측치 처리 후 확인\n",
    "df_raw.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 분리:목표변수/설명변수 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 목표변수/설명변수 분리\n",
    "df_raw_x = df_raw.drop(\"BAD\", axis = 1, inplace = False)\n",
    "df_raw_y = df_raw[\"BAD\"] \n",
    "\n",
    "display(\"설명변수:\", df_raw_x.head())\n",
    "display(\"목표변수:\",df_raw_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 범주형 설명변수 더미변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 범주형 변수 선택 : select_dtypes=\"object\" \n",
    "df_raw_x_char = df_raw_x.select_dtypes(include = \"object\")\n",
    "df_raw_x_char.head()\n",
    "\n",
    "# get_dummies: 범주형 변수에 대한 더미변환 \n",
    "df_x_dummy = pd.get_dummies(df_raw_x_char)\n",
    "df_x_dummy.head()\n",
    "\n",
    "display(\"Dummy 변환 전:\", df_raw_x_char.head())\n",
    "display(\"Dummy 변환 후:\",df_x_dummy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 연속형 설명변수 scaling 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속형 변수 선택 : select_dtypes=\"object\" 제외\n",
    "df_raw_x_num = df_raw_x.select_dtypes(exclude = \"object\")\n",
    "\n",
    "# 변수명 저장\n",
    "v_feature_names = df_raw_x_num.columns\n",
    "\n",
    "# StandardScaler 적용\n",
    "scaler = StandardScaler()\n",
    "df_x_scaled = scaler.fit_transform(df_raw_x_num)\n",
    "df_x_scaled = pd.DataFrame(df_x_scaled, columns=v_feature_names)\n",
    "\n",
    "display(\"Scale 변환 전:\", df_raw_x_num.head())\n",
    "display(\"Scale 변환 후:\",df_x_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 설명변수 데이터 결합: scale된 연속형 + dummy된 범주형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"원래 설명변수:\", df_raw_x.head(3))\n",
    "\n",
    "# 원래 연속형(df_raw_x_num) + dummy된 범주형(df_x_dummy)\n",
    "df_x_raw_dummy = df_raw_x_num.join(df_x_dummy)\n",
    "display(\"원래 연속형+ Dummied 범주형...DT/RF/GB 용:\",df_x_raw_dummy.head(3))\n",
    "\n",
    "# scale된 연속형(df_x_scaled)+ dummy된 범주형(df_x_dummy)\n",
    "df_x_scale_dummy = df_x_scaled.join(df_x_dummy)\n",
    "display(\"Scaled 연속형+ Dummied 범주형...SVM/NN/KNN 용:\",df_x_scale_dummy.head(3))\n",
    "\n",
    "# scale된 연속형(df_x_scaled) + 원래 범주형(df_raw_x_char)\n",
    "df_x_scale_raw = df_x_scaled.join(df_raw_x_char)\n",
    "display(\"Scaled 연속형+ 원래 범주형...회귀분석용(표준화 회귀계수):\",df_x_scale_raw.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 분할:Train vs. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래 연속형+ Dummied 범주형...DT/RF/GB 용:df_x_raw_dummy\n",
    "df_train_x_rd, df_test_x_rd, df_train_y, df_test_y = train_test_split(df_x_raw_dummy, df_raw_y\n",
    "                                    , test_size = 0.3, random_state = 1234)\n",
    "\n",
    "display(\"원래 연속형+ Dummied 범주형...DT/RF/GB 용:\", df_train_x_rd.head())\n",
    "\n",
    "# 기계학습용 데이터(Scaled 연속형+ Dummied 범주형) 분할:df_x_scale_dummy \n",
    "df_train_x_sd, df_test_x_sd, df_train_y, df_test_y = train_test_split(df_x_scale_dummy, df_raw_y\n",
    "                                    , test_size = 0.3, random_state = 1234)\n",
    "\n",
    "display(\"Scaled 연속형+ Dummied 범주형...SVM/NN/KNN 용:\", df_train_x_sd.head())\n",
    "\n",
    "# 회귀분석용(표준화 회귀계수) 데이터(Scaled 연속형+ 원래 범주형) 분할:df_x_scale_raw \n",
    "df_train_x_reg, df_test_x_reg, df_train_y, df_test_y = train_test_split(df_x_scale_raw, df_raw_y\n",
    "                                    , test_size = 0.3, random_state = 1234)\n",
    "\n",
    "display(\"Scaled 연속형+ 원래 범주형...회귀분석용(표준화 회귀계수):\",df_train_x_reg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 모델 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평가 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석 모델 리스트\n",
    "model = [\"DecisionTree\", \"RandomForest\", \"GradientBoosting\", \"NeuralNet\"]\n",
    "\n",
    "# 정확도 저장\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# auc score 저장\n",
    "model_auc = []\n",
    "\n",
    "# Precision, Recall score 저장\n",
    "model_precision = []; model_recall = []\n",
    "# f1 score 저장\n",
    "model_f1_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @의사결정나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종모델\n",
    "dt_final = DecisionTreeClassifier(max_depth=7, min_samples_split=50, min_samples_leaf=14, random_state=1234)\n",
    "dt_final.fit(df_train_x_rd, df_train_y)\n",
    "\n",
    "# 정확도\n",
    "train_accuracy.append(dt_final.score(df_train_x_rd, df_train_y))\n",
    "test_accuracy.append(dt_final.score(df_test_x_rd, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_prob_1 = dt_final.predict_proba(df_test_x_rd)[:, 1]  # 1 발생 확률\n",
    "y_pred = dt_final.predict(df_test_x_rd)  # 1/0 판정\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "print(classification_report(df_test_y, y_pred, digits=3))\n",
    "\n",
    "# fpr(=1-특이도) = FP/(FP+TN): 거짓 양성 비율, tpr(=민감도) = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_prob_1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P(y=1) 확률...\", y_prob_1)\n",
    "print()\n",
    "print(\"1/0-판정...\",y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Decision Tree\")\n",
    "plt.plot(fpr, tpr, label= \"AUC = %0.2f\"% roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(\"민감도,TPR\"); plt.xlabel(\"1-특이도,FPR\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### precision, recall, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))\n",
    "model_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 모델\n",
    "rf_final = RandomForestClassifier(min_samples_leaf=20, max_depth=6, n_estimators=100, random_state=1234)\n",
    "rf_final.fit(df_train_x_rd, df_train_y)\n",
    "\n",
    "# 정확도\n",
    "train_accuracy.append(rf_final.score(df_train_x_rd, df_train_y))\n",
    "test_accuracy.append(rf_final.score(df_test_x_rd, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_prob_1 = rf_final.predict_proba(df_test_x_rd)[:, 1]  # 1 발생 확률\n",
    "y_pred = rf_final.predict(df_test_x_rd)  # 1/0 판정\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "print(classification_report(df_test_y, y_pred, digits=3))\n",
    "\n",
    "# fpr(=1-특이도) = FP/(FP+TN): 거짓 양성 비율, tpr(=민감도) = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_prob_1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Random Forest\")\n",
    "plt.plot(fpr, tpr, label= \"AUC = %0.2f\"% roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(\"민감도,TPR\"); plt.xlabel(\"1-특이도,FPR\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### precision, recall, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))\n",
    "model_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래디언트 부스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 모델\n",
    "gb_final = GradientBoostingClassifier(min_samples_leaf=15, max_depth=6, n_estimators=100,\n",
    "\t\t\t learning_rate=0.1, random_state=1234)\n",
    "gb_final.fit(df_train_x_rd, df_train_y)\n",
    "\n",
    "# 정확도\n",
    "train_accuracy.append(gb_final.score(df_train_x_rd, df_train_y))\n",
    "test_accuracy.append(gb_final.score(df_test_x_rd, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_prob_1 = gb_final.predict_proba(df_test_x_rd)[:, 1]  # 1 발생 확률\n",
    "y_pred = gb_final.predict(df_test_x_rd)  # 1/0 판정\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)),\"\\n\")\n",
    "print(classification_report(df_test_y, y_pred, digits=3))\n",
    "\n",
    "# fpr(=1-특이도) = FP/(FP+TN): 거짓 양성 비율, tpr(=민감도) = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_prob_1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Grdient Boosting\")\n",
    "plt.plot(fpr, tpr, label= \"AUC = %0.2f\"% roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(\"민감도,TPR\"); plt.xlabel(\"1-특이도,FPR\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### precision, recall, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))\n",
    "model_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인공신경망\n",
    "    * df_train_x_sd/df_test_x_sd (Scaled 연속형+ Dummied 범주형) 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 모델\n",
    "nn_final = MLPClassifier(hidden_layer_sizes=(80, 80), activation=\"relu\", solver=\"adam\", random_state = 1234)\n",
    "nn_final.fit(df_train_x_sd, df_train_y)\n",
    "\n",
    "# 정확도\n",
    "train_accuracy.append(nn_final.score(df_train_x_sd, df_train_y))\n",
    "test_accuracy.append(nn_final.score(df_test_x_sd, df_test_y))\n",
    "\n",
    "# 예측값\n",
    "y_prob_1 = nn_final.predict_proba(df_test_x_sd)[:, 1]  # 1 발생 확률\n",
    "y_pred = nn_final.predict(df_test_x_sd)  # 1/0 판정\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)),\"\\n\")\n",
    "print(classification_report(df_test_y, y_pred, digits=3))\n",
    "\n",
    "# fpr(=1-특이도) = FP/(FP+TN): 거짓 양성 비율, tpr(=민감도) = TP/(TP+FN): 진짜 양성 비율(재현율)\n",
    "fpr, tpr, thresholds = roc_curve(df_test_y, y_prob_1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# auc 저장\n",
    "model_auc.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Neural Network\")\n",
    "plt.plot(fpr, tpr, label= \"AUC = %0.2f\"% roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(\"민감도,TPR\"); plt.xlabel(\"1-특이도,FPR\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### precision, recall, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision, recall score\n",
    "model_precision.append(precision_score(df_test_y, y_pred))\n",
    "model_recall.append(recall_score(df_test_y, y_pred))\n",
    "\n",
    "# f1 score\n",
    "model_f1_score.append(f1_score(df_test_y, y_pred))\n",
    "model_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델별 정확도 산출 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # 모델별 평가 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 평가 결과\n",
    "df_eval = pd.DataFrame(index = model)\n",
    "df_eval[\"TrainAccuracy\"] = train_accuracy ; df_eval[\"TestAccuracy\"] = test_accuracy\n",
    "df_eval[\"AUC\"] = model_auc\n",
    "\n",
    "df_eval[\"Precision\"] = model_precision; df_eval[\"Recall\"] = model_recall\n",
    "df_eval[\"F1Score\"] = model_f1_score\n",
    "\n",
    "df_eval.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # 모델별 평가 지표 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 평가 지표 확인\n",
    "df_eval.plot.bar(rot = 0, figsize=(10,4))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(axis = \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 인공 신경망 모델이 가장 높은 정확도와 F1 score, AUC를 보임\n",
    "* NeuralNet > GradientBoosting > DecisionTree > RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of 모델평가"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
