{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 구성:Series, DataFrame\n",
    "import pandas as pd\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 데이터 분할:train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 분류 Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# 최적 모델, 파라미터 탐색\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 분류모델 평가 함수\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래프 옵션 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 한글폰트 적용:맑은 고딕\n",
    "matplotlib.rc(\"font\", family = \"Malgun Gothic\")\n",
    "# 그래프 (-) 기호 표시\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df_raw = pd.read_csv(\"D:/WORK/DATA/HMEQ.CSV\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 구조 확인\n",
    "print(\"Data 구조:\", df_raw.shape)\n",
    "print()\n",
    "print(\"변수 : \", df_raw.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인\n",
    "df_raw.isnull().sum(axis = 0)\n",
    "\n",
    "# 결측치 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna: 결측치를 채우는 함수\n",
    "# JOB 변수의 결측치는 Other로 입력, inplace: fillna 함수 적용 후 ds_hmeq 데이터에 저장, False면 저장 안 함\n",
    "df_raw[\"JOB\"].fillna(\"Other\", inplace = True)\n",
    "\n",
    "# 숫자형 변수의 결측치는 해당 변수의 평균값 입력: ds_hmeq.mean() 각 변수별 평균 계산 후 결측치 대체\n",
    "df_raw.fillna(df_raw.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 재확인\n",
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 범주형 설명변수 더미 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies: 데이터의 문자형 변수에 대한 더미변수 생성 \n",
    "df_raw_dummy = pd.get_dummies(df_raw)\n",
    "df_raw_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 분리: 목표변수 vs. 설명변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수, 목표변수 데이터 구분\n",
    "df_raw_x = df_raw_dummy.drop(\"BAD\", axis = 1, inplace = False)\n",
    "df_raw_y = df_raw_dummy[\"BAD\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 train_test_split(X: 설명변수, Y: 목표변수, test_size = test 데이터 비율)\n",
    "df_train_x, df_test_x, df_train_y, df_test_y = train_test_split(\n",
    "    df_raw_x, df_raw_y, test_size = 0.3, random_state = 1234) \n",
    "\n",
    "print(\"분할 전 설명변수 데이터 :\", df_raw_x.shape)\n",
    "print(\"분할 후 설명변수 데이터 :Train\", df_train_x.shape, \"  Test\",df_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_raw.head(10))\n",
    "display(df_raw_x.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 구조 확인\n",
    "print(\"Data 구조:\", df_raw_x.columns)\n",
    "print()\n",
    "print(\"변수 : \", df_train_x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 옵션 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래디언트 부스팅 모델 생성: GradientBoostingClassifier\n",
    "gb_uncust = GradientBoostingClassifier(random_state=1234)\n",
    "gb_uncust.fit(df_train_x, df_train_y)\n",
    "\n",
    "# train 모델 정확도\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gb_uncust.score (df_train_x, df_train_y)))\n",
    "# test 모델 정확도\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gb_uncust.score (df_test_x, df_test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행옵션 확인\n",
    "print(gb_uncust.get_params().keys())\n",
    "print(gb_uncust.get_params().values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @learning_rate(학습률) 변화에 따른 모델 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# learning_rate 학습률 변경\n",
    "para_lr = [lr * 0.1 for lr in range(1, 10)]\n",
    "# para_lr = [lr * 0.02 for lr in range(1, 20)]   # 민감하게 변화하면 0.02 간격으로 확인\n",
    "\n",
    "for v_learning_rate in para_lr:\n",
    "    gb = GradientBoostingClassifier(learning_rate = v_learning_rate, random_state = 1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_lr = pd.DataFrame()\n",
    "df_accuracy_lr[\"LearningRate\"] = para_lr\n",
    "df_accuracy_lr[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_lr[\"TestAccuracy\"] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LearningRate별 정확도 \n",
    "df_accuracy_lr.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LearningRate별 정확도 그래프 확인\n",
    "plt.plot(para_lr, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_lr, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"learning rate\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 학습률 지정 : 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @n_estimators: 트리의 개수 변경에 따른 모델 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# n_estimatos: 트리 수 변경\n",
    "para_n_tree = [n_tree * 10 for n_tree in range(1, 16)]\n",
    "\n",
    "for v_n_estimators in para_n_tree:\n",
    "    gb = GradientBoostingClassifier(n_estimators = v_n_estimators, learning_rate=0.1, random_state=1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_n = pd.DataFrame()\n",
    "df_accuracy_n[\"Estimators\"] = para_n_tree\n",
    "df_accuracy_n[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_n[\"TestAccuracy\"] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_n_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators별 정확도 \n",
    "df_accuracy_n.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도를 그래프 확인\n",
    "plt.plot(para_n_tree, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_n_tree, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"n_estimators\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 트리 수 지정 :100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @max_depth: 최대 깊이 변경에 따른 모델 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# max_depth: 최대 깊이 변경. 1~10\n",
    "para_depth = [depth for depth in range(1, 11)]\n",
    "\n",
    "for v_max_depth in para_depth:\n",
    "    gb = GradientBoostingClassifier(max_depth = v_max_depth,\n",
    "                            n_estimators=100, learning_rate=0.1, random_state=1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_depth = pd.DataFrame()\n",
    "df_accuracy_depth[\"Depth\"] = para_depth\n",
    "df_accuracy_depth[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_depth[\"TestAccuracy\"] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth별 정확도\n",
    "df_accuracy_depth.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도를 그래프 확인\n",
    "plt.plot(para_depth, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_depth, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"depth\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 최대 깊이 지정:6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @min_samples_split: 분리 노드의 최소 샘플 수 변경에 따른 모델 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# min_samples_split: 분할하기 위한 노드의 최소 샘플 수. 20~100\n",
    "para_split = [n_split * 10 for n_split in range(2, 11)]\n",
    "\n",
    "for v_min_samples_split in para_split:\n",
    "    gb = GradientBoostingClassifier(min_samples_split = v_min_samples_split,\n",
    "                                    max_depth=6, n_estimators=100, learning_rate=0.1, random_state=1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_split = pd.DataFrame()\n",
    "df_accuracy_split[\"MinSamplesSplit\"] = para_split\n",
    "df_accuracy_split[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_split[\"TestAccuracy\"] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf별 정확도 \n",
    "df_accuracy_split.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도를 그래프 확인\n",
    "plt.plot(para_split, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_split, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"min samples split\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# min_samples_split: 분리 노드의 최소 샘플 수 미지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @min_samples_leaf: leaf 수 변경에 따른 모델 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 및 test 정확도 결과 저장용\n",
    "train_accuracy = []; test_accuracy = []\n",
    "# min_samples_leaf: 잎사귀 노드 최소 자료 수. 5~50\n",
    "para_leaf = [n_leaf * 5 for n_leaf in range(1, 11)]\n",
    "\n",
    "for v_min_samples_leaf in para_leaf:\n",
    "    gb = GradientBoostingClassifier(min_samples_leaf = v_min_samples_leaf,\n",
    "                                     max_depth=6, n_estimators=100, learning_rate=0.1, random_state=1234)\n",
    "    gb.fit(df_train_x, df_train_y)\n",
    "    train_accuracy.append(gb.score(df_train_x, df_train_y))\n",
    "    test_accuracy.append(gb.score(df_test_x, df_test_y))\n",
    "\n",
    "# 데이터 테이블로 저장\n",
    "df_accuracy_leaf = pd.DataFrame()\n",
    "df_accuracy_leaf[\"MinSamplesLeaf\"] = para_leaf\n",
    "df_accuracy_leaf[\"TrainAccuracy\"] = train_accuracy\n",
    "df_accuracy_leaf[\"TestAccuracy\"] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf별 정확도 \n",
    "df_accuracy_leaf.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도를 그래프 확인\n",
    "plt.plot(para_leaf, train_accuracy, linestyle = \"-\", label = \"Train Accuracy\")\n",
    "plt.plot(para_leaf, test_accuracy, linestyle = \"--\", label = \"Test Accuracy\")\n",
    "plt.ylabel(\"accuracy\"); plt.xlabel(\"min samples leaf\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 잎사귀 노드의 최소 자료 수 지정:15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론 도출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 모델\n",
    "gb_final = GradientBoostingClassifier(min_samples_leaf=15, max_depth=6, n_estimators=100, learning_rate=0.1, \n",
    "                                      random_state=1234)\n",
    "gb_final.fit(df_train_x, df_train_y)\n",
    "# 예측\n",
    "y_pred = gb_final.predict(df_test_x)\n",
    "\n",
    "# train 모델 정확도\n",
    "print(\"Train Accuracy: {:.3f}\".format(gb_final.score(df_train_x, df_train_y)))\n",
    "# test 모델 정확도\n",
    "print(\"Test Accuracy: {:.3f}\\n\".format(gb_final.score(df_test_x, df_test_y)))\n",
    "# confusion matrix\n",
    "print(\"Test Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "\n",
    "# 목표변수의 빈도 불균형 : f1 score로 모델 평가 \n",
    "print(classification_report(df_test_y, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 설명변수 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명\n",
    "v_feature_name = df_train_x.columns\n",
    "# tree.feature_importances_로 설명변수 중요도 확인 및 테이블로 저장\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance [\"Feature\"] = v_feature_name\n",
    "df_importance [\"Importance\"] = gb_final.feature_importances_\n",
    "# df_feature_importance의 테이블을 중요도별로 정렬\n",
    "df_importance .sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_importance .round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수 중요도 그래프\n",
    "# 중요도가 높은 변수를 상위에 그림 \n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "df_importance .sort_values(\"Importance\", ascending=True, inplace = True)\n",
    "coordinates = range(len(df_importance ))\n",
    "plt.barh(y = coordinates, width = df_importance [\"Importance\"])\n",
    "plt.yticks(coordinates, df_importance [\"Feature\"])\n",
    "plt.xlabel(\"설명변수 중요도\")\n",
    "plt.ylabel(\"설명변수\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참조:Grid Search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "estimator = GradientBoostingClassifier(n_estimators=100, random_state=1234)\n",
    "# 구하고자 하는 parameter와 범위\n",
    "param_grid = {\"learning_rate\": para_lr,\n",
    "              \"max_depth\": para_depth,\n",
    "              \"min_samples_leaf\": para_leaf}\n",
    "# 정확도가 높은 최적 parameter 찾기\n",
    "grid_gb = GridSearchCV(estimator, param_grid, scoring=\"accuracy\", n_jobs = -1)\n",
    "grid_gb.fit(df_train_x, df_train_y)\n",
    "print(\"best estimator model: \\n{}\".format(grid_gb.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(grid_gb.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(grid_gb.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @xgboost 연습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @sklearn Framework 기반의 XGBoost 연습\n",
    "\n",
    "특징\n",
    ". 사이킷런의 기본 Estimator를 이용해 만들어 fit()과 predict()만으로 학습과 예측이 가능\n",
    "\n",
    ". GridSearchCV,Pipeline 등 사이킷런의 유틸리티를 그대로 사용 가능\n",
    ". 분류 : XGBClassifier / 회귀 : XGBRegressor\n",
    "\n",
    "eta → learning_rate\n",
    "sub_sample → subsample\n",
    "lambda → reg_lambda\n",
    "alpha → reg_alpha\n",
    "num_boost_round → n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost 패키지 불러오기 \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 변수 중요도 확인: F1 점수 기준\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# 분류모델 통합 평가: 혼동행렬, 정확도, 정밀도, 재현율, F1, AUC 등\n",
    "def eval_class_model(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    print('오차행렬:\\n', confusion, '\\n')\n",
    "    print('정확도: {:.4f}'.format(accuracy))\n",
    "    print('정밀도: {:.4f}'.format(precision))\n",
    "    print('재현율: {:.4f}'.format(recall))\n",
    "    print('F1    : {:.4f}'.format(F1))\n",
    "    print('AUC   : {:.4f}'.format(AUC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 기본 모델 지정 및 기본 옵션 확인\n",
    "xgboost_uncust = XGBClassifier(random_state=1234)\n",
    "\n",
    "xgboost_uncust\n",
    "# xgboost_uncust.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 적합\n",
    "xgboost_uncust.fit(df_train_x, df_train_y)\n",
    "\n",
    "print('\\n 모델 생성 및 평가 : Train \\n')\n",
    "# 예측 및 모델 평가:train  \n",
    "xgb_pred_train = xgboost_uncust.predict(df_train_x)\n",
    "# 모델 평가\n",
    "eval_class_model(df_train_y, xgb_pred_train)\n",
    "\n",
    "print('\\n 모델 생성 및 평가 : Test \\n')\n",
    "# 예측 및 모델 평가:test \n",
    "xgb_pred_test = xgboost_uncust.predict(df_test_x)\n",
    "# 모델 평가\n",
    "eval_class_model(df_test_y, xgb_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 모델 생성\n",
    "xgboost_user= XGBClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 5, random_state=1234)\n",
    "# 모델 적합\n",
    "xgboost_user.fit(df_train_x, df_train_y)\n",
    "\n",
    "# 예측 및 모델 평가:Train  \n",
    "xgb_pred_train = xgboost_user.predict(df_train_x)\n",
    "\n",
    "print('\\n 사용자 모델 평가 : Train \\n')\n",
    "eval_class_model(df_train_y, xgb_pred_train)\n",
    "print('\\n',classification_report(df_train_y, xgb_pred_train))\n",
    "\n",
    "\n",
    "# 예측 및 모델 평가:Test  \n",
    "xgb_pred_test = xgboost_user.predict(df_test_x)\n",
    "\n",
    "print('\\n 사용자 모델 평가 : Test \\n')\n",
    "eval_class_model(df_test_y, xgb_pred_test)\n",
    "print('\\n',classification_report(df_test_y, xgb_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sklearn XGBoost 모델의 조기 중단:fit( )에 파라미터 입력(early_stopping_rounds, eval_metrics, eval_set.)\n",
    "# 모델 파라미터 지정:n_estimators, learning_rate, max_depth 등 지정\n",
    "# 조기 중간 파라미터 지정: early_stopping_rounds \n",
    "# 평가지표 지정:logloss\n",
    "\n",
    "# 모델 성능 평가 데이터\n",
    "eval_df = [(df_test_x, df_test_y)]\n",
    "\n",
    "xgb_stop = XGBClassifier(n_estimators = 300, learning_rate = 0.1 , max_depth = 6, random_state=1234)\n",
    "xgb_stop.fit(df_train_x, df_train_y, \n",
    "            # 조기 중단 파라미터\n",
    "             early_stopping_rounds = 150, eval_metric=\"logloss\", eval_set = eval_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델 정보 확인\n",
    "print(\"최적 횟수:\",xgb_stop.best_iteration)  \n",
    "print(\"최적 성능(0-LogLoss):\",xgb_stop.best_score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 최적 모델 평가\n",
    "xgb_pred_stop = xgb_stop.predict(df_test_x)\n",
    "\n",
    "print('\\n 조기 중단 모델 평가 : Test \\n')\n",
    "eval_class_model(df_test_y, xgb_pred_stop)\n",
    "print('\\n',classification_report(df_test_y, xgb_pred_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 중요도 확인 \n",
    "from xgboost import plot_importance  # F1 score 기준으로 변수 중요도 표시(변경 가능)\n",
    "print(xgb_stop.get_booster().get_fscore())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plot_importance(xgb_stop, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_type 변경 가능\n",
    "# plot_importance(xgb_stop, importance_type='gain', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @LightGBM 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package 설치\n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @sklearn Framework 기반의 LightGBM 연습\n",
    "\n",
    "* 설치 : !pip install lightgbm 또는 conda install lightgbm\n",
    "\n",
    "* 특징\n",
    "    - Leaf-wise 분할방식: 최대 손실 값을 가지는 리프 노드를 지속적으로 분할 -> 비대칭 트리가 생성됨\n",
    "    - XGBoost 보다 학습 소요시간 및 메모리 등 시스템 자원 사용량이 상대적으로 적다\n",
    "    - 범주형 설명변수의 자동 변환과 최적 분할 지원(One-Hot Encoding을 적용하지 않아도 분할 가능)\n",
    "\n",
    "* 모델 : 분류-LGBMClassifier, 예측-LGBMRegressor\n",
    "\n",
    "* 주요 Hyper-parameter\n",
    "        - n_estimators [default: 100]: GBM과 XGB의 n_estimators와 같은 파라미터\n",
    "\n",
    "learning_rate [defalut: 0.1]: GBM과 XGB의 학습률(learning_rate)과 같은 파라미터, 일반적으로 n_estimators를 높이고 learning_rate를 낮추면 예측 성능이 향상하지만 마찬가지로 과적합 이슈 및 소요 시간 증가의 문제가 있다.\n",
    "\n",
    "max_depth [default: 1]: 트리 기반 알고리즘의 max_depth와 같다. 0보다 작은 값을 지정하면 깊이 제한이 없다. LightGBM은 Leaf Wise 방식이므로 깊이가 상대적으로 더 깊다.\n",
    "\n",
    "min_child_samples [default: 20]: 결정 트리의 min_samples_leaf와 같은 파라미터로 리프 노드가 되기 위해 최소한으로 필요한 샘플 수\n",
    "\n",
    "num_leaves [default: 31]: 하나의 트리가 가질 수 있는 최대 리프 개수\n",
    "\n",
    "boosting [default: gbdt]: 부스팅의 트리를 생성하는 알고리즘을 지정하며 gbdt는 일반적인 그래디언트 부스팅 결정 트리이며 rf는 랜덤 포레스트이다.\n",
    "\n",
    "subsample [default: 1]: GBM과 XGB의 subsample과 같은 파라미터\n",
    "\n",
    "colsample_bytree [default: 1]: XGB의 colsample_bytree와 같은 파라미터로 개별 트리를 학습할 때마다 무작위로 선택하는 피처의 비율\n",
    "\n",
    "reg_lambda [default: 0]: XGB의 reg_lambda와 같은 파라미터로 L2 regulation 제어를 위한 값이다. 피처 개수가 많을 경우 적용을 검토하며 값이 클수록 과적합 감소 효과가 있다.\n",
    "\n",
    "reg_alpha [default: 0]: XGB의 reg_alpha와 같은 파라미터로 L1 regulation 제어를 위한 값이다. 피처 개수가 많을 경우 적용을 검토하며 값이 클수록 과적합 감소 효과가 있다.\n",
    "\n",
    "학습 태스크 파라미터\n",
    "\n",
    "objective: 최솟값을 가져야할 손실함수를 정의한다. XGB의 objective 파라미터와 동일하다.\n",
    "\n",
    "    - num_leaves:개별 트리가 가질 수 있는 최대 리프 수\n",
    "    - min_data_in_leaf:리프의 최소 자료 수. min_child_samples\n",
    "    - max_depth:최대 (가능) 깊이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 패키지 불러오기 \n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 변수 중요도 확인: F1 점수 기준\n",
    "from lightgbm import plot_importance\n",
    "\n",
    "# 분류모델 통합 평가: 혼동행렬, 정확도, 정밀도, 재현율, F1, AUC 등\n",
    "def eval_class_model(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    print('오차행렬:\\n', confusion, '\\n')\n",
    "    print('정확도: {:.4f}'.format(accuracy))\n",
    "    print('정밀도: {:.4f}'.format(precision))\n",
    "    print('재현율: {:.4f}'.format(recall))\n",
    "    print('F1    : {:.4f}'.format(F1))\n",
    "    print('AUC   : {:.4f}'.format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 기본 모델 지정 및 기본 옵션 확인\n",
    "lgbm_uncust = LGBMClassifier(random_state=1234)\n",
    "\n",
    "lgbm_uncust.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 모델 적합\n",
    "lgbm_uncust.fit(df_train_x, df_train_y)\n",
    "print('\\n 모델 생성 및 평가 : Train \\n')\n",
    "# 예측 및 모델 평가:train  \n",
    "lgbm_pred_train = lgbm_uncust.predict(df_train_x)\n",
    "eval_class_model(df_train_y, lgbm_pred_train)\n",
    "print('\\n 모델 생성 및 평가 : Test \\n')\n",
    "# 예측 및 모델 평가:test \n",
    "lgbm_pred_test = lgbm_uncust.predict(df_test_x)\n",
    "eval_class_model(df_test_y, lgbm_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 모델 생성\n",
    "lgbm_user= LGBMClassifier(n_estimators = 100, learning_rate = 0.1, max_depth = 6, random_state=1234)\n",
    "# 모델 적합\n",
    "lgbm_user.fit(df_train_x, df_train_y)\n",
    "\n",
    "# 예측 및 모델 평가:Train  \n",
    "lgbm_pred_train = lgbm_user.predict(df_train_x)\n",
    "\n",
    "print('\\n 사용자 모델 평가 : Train \\n')\n",
    "eval_class_model(df_train_y, lgbm_pred_train)\n",
    "print('\\n',classification_report(df_train_y, lgbm_pred_train))\n",
    "\n",
    "# 예측 및 모델 평가:Test  \n",
    "lgbm_pred_test = lgbm_user.predict(df_test_x)\n",
    "\n",
    "print('\\n 사용자 모델 평가 : Test \\n')\n",
    "eval_class_model(df_test_y, lgbm_pred_test)\n",
    "print('\\n',classification_report(df_test_y, lgbm_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sklearn lightgbm 모델의 조기 중단 : fit( )에 파라미터 입력(early_stopping_rounds, eval_metrics, eval_set.)\n",
    "# 모델 파라미터 지정:n_estimators, learning_rate, max_depth 등 지정\n",
    "# 조기 중간 파라미터 지정: early_stopping_rounds \n",
    "# 평가지표 지정:logloss\n",
    "eval_df = [(df_test_x, df_test_y)]\n",
    "\n",
    "lgbm_stop = LGBMClassifier(n_estimators = 300, learning_rate = 0.1, max_depth = 6, random_state=1234)\n",
    "# lgbm_stop = LGBMClassifier(n_estimators = 300, learning_rate = 0.1, max_depth = 6,\n",
    "#                           reg_alpha=0.2)\n",
    "\n",
    "# 모델 성능 평가 데이터\n",
    "lgbm_stop.fit(df_train_x, df_train_y, \n",
    "              # 조기 중단 파라미터\n",
    "              early_stopping_rounds = 200, eval_metric=\"logloss\", eval_set = eval_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 최적모델 정보 확인\n",
    "print(\"최적 횟수:\",lgbm_stop.best_iteration_)  \n",
    "print(\"최적 성능(0-LogLoss):\",lgbm_stop.best_score_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참조!!! 모델 결과 확인\n",
    "print(lgbm_stop.boosting_type)  # gbdt\n",
    "print(lgbm_stop.class_weight)  # None\n",
    "print(lgbm_stop.classes_)  # [0 1]\n",
    "print(lgbm_stop.colsample_bytree)  # 1.0\n",
    "# print(lgbm_stop.evals_result_)  # {'valid_0': OrderedDict([('binary_logloss', [0.28510\n",
    "\n",
    "# print(lgbm_stop.evals_result_)  # \n",
    "print(lgbm_stop.feature_name_)  # \n",
    "print(lgbm_stop.feature_importances_)  # \n",
    "\n",
    "print(lgbm_stop.fit)  # <bound method LGBMClassifier.fit of LGBMClassifier(max_depth=6, n_estimators=300)>\n",
    "print(lgbm_stop.fitted_)  # True\n",
    "print(lgbm_stop.importance_type)  # split\n",
    "\n",
    "\n",
    "print(lgbm_stop.learning_rate)  # 0.1\n",
    "print(lgbm_stop.min_child_samples)  # 20 \n",
    "print(lgbm_stop.n_classes_)  # 2\n",
    "print(lgbm_stop.num_leaves)  # 31\n",
    "print(lgbm_stop.objective)  # None\n",
    "print(lgbm_stop.objective_)  # binary\n",
    "print(lgbm_stop.predict)  # \n",
    "print(lgbm_stop.predict_proba)  # \n",
    "print(lgbm_stop.reg_alpha)  # 0.0\n",
    "print(lgbm_stop.reg_lambda)  # 0.0\n",
    "print(lgbm_stop.subsample_for_bin)  # 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 최적 모델 평가\n",
    "lgbm_pred_stop = lgbm_stop.predict(df_test_x)\n",
    "\n",
    "print('\\n 조기 중단 모델 평가 : Test \\n')\n",
    "eval_class_model(df_test_y, lgbm_pred_stop)\n",
    "print('\\n',classification_report(df_test_y, lgbm_pred_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 변수 중요도 확인 \n",
    "from lightgbm import plot_importance\n",
    "print(lgbm_stop.feature_name_)\n",
    "print(lgbm_stop.feature_importances_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plot_importance(lgbm_stop, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @Categorical Boosting 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package 설치\n",
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기 \n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 변수 중요도 확인: CatBoost는 plot_importance 함수 미지원\n",
    "\n",
    "# 분류모델 통합 평가: 혼동행렬, 정확도, 정밀도, 재현율, F1, AUC 등\n",
    "def eval_class_model(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    print('오차행렬:\\n', confusion, '\\n')\n",
    "    print('정확도: {:.4f}'.format(accuracy))\n",
    "    print('정밀도: {:.4f}'.format(precision))\n",
    "    print('재현율: {:.4f}'.format(recall))\n",
    "    print('F1    : {:.4f}'.format(F1))\n",
    "    print('AUC   : {:.4f}'.format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 기본 모델 지정 및 기본 옵션 확인\n",
    "cbc_uncust = CatBoostClassifier(random_state=1234)\n",
    "\n",
    "cbc_uncust.get_all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 적합\n",
    "cbc_uncust.fit(df_train_x, df_train_y)\n",
    "\n",
    "print('\\n 모델 생성 및 평가 : Train \\n')\n",
    "# 예측 및 모델 평가:train  \n",
    "cbc_pred_train = cbc_uncust.predict(df_train_x)\n",
    "eval_class_model(df_train_y, cbc_pred_train)\n",
    "\n",
    "print('\\n 모델 생성 및 평가 : Test \\n')\n",
    "# 예측 및 모델 평가:test \n",
    "cbc_pred_test = cbc_uncust.predict(df_test_x)\n",
    "eval_class_model(df_test_y, cbc_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 사용자 모델 생성\n",
    "cbc_user= CatBoostClassifier(n_estimators = 200, learning_rate = 0.1, max_depth = 6, random_state=1234)\n",
    "# 모델 적합\n",
    "cbc_user.fit(df_train_x, df_train_y)\n",
    "\n",
    "# 예측 및 모델 평가:Train  \n",
    "cbc_pred_train = cbc_user.predict(df_train_x)\n",
    "\n",
    "print('\\n 사용자 모델 평가 : Train \\n')\n",
    "eval_class_model(df_train_y, cbc_pred_train)\n",
    "print('\\n',classification_report(df_train_y, cbc_pred_train))\n",
    "\n",
    "\n",
    "# 예측 및 모델 평가:Test  \n",
    "cbc_pred_test = cbc_user.predict(df_test_x)\n",
    "\n",
    "print('\\n 사용자 모델 평가 : Test \\n')\n",
    "eval_class_model(df_test_y, cbc_pred_test)\n",
    "print('\\n',classification_report(df_test_y, cbc_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CatBoost 모델의 조기 중단:fit( )에 파라미터 입력(early_stopping_rounds, eval_metrics, eval_set.)\n",
    "# 모델 파라미터 지정:n_estimators, learning_rate, max_depth 등 지정\n",
    "# 조기 중간 파라미터 지정: early_stopping_rounds \n",
    "# 평가지표 지정:logloss\n",
    "\n",
    "# 모델 성능 평가 데이터\n",
    "eval_df = [(df_test_x, df_test_y)]\n",
    "\n",
    "cbc_stop = CatBoostClassifier(n_estimators = 300, learning_rate = 0.1 , max_depth = 6, random_state=1234)\n",
    "\n",
    "cbc_stop.fit(df_train_x, df_train_y, \n",
    "            # 조기 중단 파라미터\n",
    "             early_stopping_rounds = 150,eval_set = eval_df, verbose=True)\n",
    "# cbc_stop.fit(df_train_x, df_train_y, \n",
    "#             # 조기 중단 파라미터\n",
    "#              early_stopping_rounds = 150, eval_metric=\"auto\", eval_set = eval_df, \n",
    "#              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적모델 정보 확인\n",
    "print(\"최적 횟수:\",cbc_stop.best_iteration_)  \n",
    "print(\"최적 성능:\",cbc_stop.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조기 중단 예측 및 모델 평가:Test  \n",
    "cbc_pred_stop = cbc_stop.predict(df_test_x)\n",
    "\n",
    "print('\\n 조기 중단 모델 평가 : Test \\n')\n",
    "eval_class_model(df_test_y, cbc_pred_stop)\n",
    "print('\\n',classification_report(df_test_y, cbc_pred_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 중요도 확인 \n",
    "print(cbc_stop.feature_names_)\n",
    "print(cbc_stop.feature_importances_)\n",
    "# print(cbc_stop.get_feature_importance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명\n",
    "v_feature_name = df_train_x.columns\n",
    "# tree.feature_importances_로 설명변수 중요도 확인 및 테이블로 저장\n",
    "df_cbc_importance = pd.DataFrame()\n",
    "df_cbc_importance [\"Feature\"] = cbc_stop.feature_names_\n",
    "df_cbc_importance [\"Importance\"] = cbc_stop.feature_importances_\n",
    "# 중요도별로 정렬\n",
    "df_cbc_importance .sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_cbc_importance .round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수 중요도 그래프\n",
    "# 중요도가 높은 변수를 상위에 그림 \n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "df_cbc_importance.sort_values(\"Importance\", ascending=True, inplace = True)\n",
    "coordinates = range(len(df_cbc_importance ))\n",
    "plt.barh(y = coordinates, width = df_cbc_importance [\"Importance\"])\n",
    "plt.yticks(coordinates, df_cbc_importance [\"Feature\"])\n",
    "plt.xlabel(\"설명변수 중요도\")\n",
    "plt.ylabel(\"설명변수\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Boosting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
