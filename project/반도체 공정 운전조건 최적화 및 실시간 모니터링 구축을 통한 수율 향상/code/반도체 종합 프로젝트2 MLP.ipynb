{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f31291a-7cd7-4526-a963-7080de7236ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ec6b9c-6806-4e9d-b00e-40c6d5446264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3790be5-7417-4254-9be6-99b07a380265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"01 Oxidation.csv\")\n",
    "df2 = pd.read_csv(\"02 Photo_softbake.csv\")\n",
    "df3 = pd.read_csv(\"03 Photo_lithograpy.csv\")\n",
    "df4 = pd.read_csv(\"04 Etching.csv\")\n",
    "df5 = pd.read_csv(\"05 Ion_Implantation.csv\")\n",
    "df6 = pd.read_csv(\"06 Inspect.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc8bad3-18cb-43f1-bd1c-7bbfc7163d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])\n",
    "df = pd.merge(df, df3, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])\n",
    "df = pd.merge(df, df4, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])\n",
    "df = pd.merge(df, df5, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])\n",
    "df = pd.merge(df, df6, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587f2b7b-5130-46f8-b82e-4d22185bb662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=\"Thin F2\", inplace=True) # 다른 변수들과의 연관성을 찾지못함, 한 행에 여러 열들 결측값 가짐\n",
    "# pd.set_option('display.max_row', 200)\n",
    "# pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b1bfdab-68c3-446d-9b13-e85be3c070e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ox_Chamber'] = df['Ox_Chamber'].astype('str')\n",
    "df['photo_soft_Chamber'] = df['photo_soft_Chamber'].astype('str')\n",
    "df['lithography_Chamber'] = df['lithography_Chamber'].astype('str')\n",
    "df['Etching_Chamber'] = df['Etching_Chamber'].astype('str')\n",
    "df['Chamber_Num'] = df['Chamber_Num'].astype('str')\n",
    "df['path'] = df['Ox_Chamber']+df['photo_soft_Chamber']+df['lithography_Chamber']+df['Etching_Chamber']+df['Chamber_Num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473e2781-842c-490c-ab04-86d823e303ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(df[df['Oxid_time']<0].index, inplace=True) # 산화시간이 음수\n",
    "df.drop(df[df['Target']==0].index, inplace=True) # target 값이 0\n",
    "df.drop(columns = [\"Wafer_map\",\"Error_message\"],inplace=True) # 웨이퍼맵, 에러메시지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1335a37d-5e7f-4308-b788-e3394e9a72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 데이터 datetime 유형으로 변환\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'], format='%d-%m-%Y')\n",
    "\n",
    "# 195이상 = 불량(1), 195미만 = 양품(0)\n",
    "df.loc[df['Target'] >= 195, '불량_195이상'] =1\n",
    "df.loc[df['Target'] < 195, '불량_195이상'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db7cfb0-e884-47a0-b1e2-b338eb40b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Thin F4']<0, 'Thin F4']=df['Thin F4'].median()\n",
    "df.loc[df['Flux90s']<0, 'Flux90s']=df['Flux90s'].median()\n",
    "df.loc[df['Flux160s']<0, 'Flux160s']=df['Flux160s'].median()\n",
    "df.loc[df['Flux160s']<5, 'Flux160s']=df['Flux160s'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acd283d7-4f43-4240-a57b-b403e041b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Thin F1'].fillna(df['Thin F1'].median(), inplace=True)\n",
    "df['Thin F3'].fillna(df['Thin F3'].median(), inplace=True)\n",
    "df['Flux60s'].fillna(df['Flux90s'].median(), inplace=True)\n",
    "df['Flux90s'].fillna(df['Flux90s'].median(), inplace=True)\n",
    "df['Flux480s'].fillna(df['Flux90s'].median(), inplace=True)\n",
    "df['Flux840s'].fillna(df['Flux90s'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4b6f3-d202-400e-9d08-81a9885dfa06",
   "metadata": {},
   "source": [
    "### 불필요한 열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a1766d-1b14-42bc-b817-57fe8c553a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 열 제거 \n",
    "# df.drop(columns=[\"No_Die\", \"Lot_Num\", \"Wafer_Num\"], inplace=True)\n",
    "df.drop(columns=['Vapor','process','Wavelength'])\n",
    "df.loc[df['Flux840s'] == 8.137500e+16, 'Flux840s'] = df['Flux840s'].mode()[0]\n",
    "df.loc[df['Flux480s'] == 8.137500e+16, 'Flux480s'] = df['Flux480s'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edecc600-f595-458e-b623-d16f3670e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['Temp_OXid','ppm','Pressure','type','Oxid_time',\n",
    "        'N2_HMDS', 'pressure_HMDS', 'temp_HMDS', 'temp_HMDS_bake',\n",
    "       'time_HMDS_bake', 'spin1', 'spin2', 'spin3', 'photoresist_bake',\n",
    "       'temp_softbake', 'time_softbake', 'UV_type', 'Energy_Exposure',       \n",
    "        'Temp_Etching', 'Source_Power',\n",
    "       'input_Energy', 'Temp_implantation', 'Furance_Temp', 'RTA_Temp',\n",
    "       '불량_195이상', 'path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32c09858-5c1b-46ad-b4f5-43fe5e7ba974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 구성:Series, DataFrame\n",
    "import pandas as pd\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 데이터 분할:train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 분류 Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# 최적 모델, 파라미터 탐색\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 분류모델 평가 함수\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "897b976d-7fcb-4a26-a444-276af007c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할 전 설명변수 데이터 : (1693, 25)\n",
      "분할 후 설명변수 데이터 :Train (1185, 25)   Test (508, 25)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df_raw_x = df_new.drop(\"불량_195이상\", axis = 1)\n",
    "df_raw_y = df_new[\"불량_195이상\"] \n",
    "\n",
    "# object 형식의 열들에 대해 Label Encoding 수행\n",
    "for column in df_raw_x.columns:\n",
    "    if df_raw_x[column].dtype == 'object':\n",
    "        df_raw_x[column] = label_encoder.fit_transform(df_raw_x[column])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 데이터 스케일링\n",
    "X_scaled = scaler.fit_transform(df_raw_x)\n",
    "\n",
    "df_train_x, df_test_x, df_train_y, df_test_y = train_test_split(\n",
    "    X_scaled, df_raw_y, test_size = 0.3, random_state = 1234, stratify=df_raw_y) \n",
    "\n",
    "print(\"분할 전 설명변수 데이터 :\", df_raw_x.shape)\n",
    "print(\"분할 후 설명변수 데이터 :Train\", df_train_x.shape, \"  Test\",df_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d61923ef-67a2-44ce-bf6b-bf7ea5047203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6994 - loss: 0.5996 - val_accuracy: 0.9367 - val_loss: 0.2451\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9226 - loss: 0.2892 - val_accuracy: 0.9367 - val_loss: 0.2242\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9298 - loss: 0.2683 - val_accuracy: 0.9367 - val_loss: 0.2150\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9269 - loss: 0.2359 - val_accuracy: 0.9367 - val_loss: 0.2092\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9164 - loss: 0.2494 - val_accuracy: 0.9367 - val_loss: 0.2056\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9162 - loss: 0.2788 - val_accuracy: 0.9367 - val_loss: 0.2028\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9338 - loss: 0.2192 - val_accuracy: 0.9367 - val_loss: 0.2015\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9030 - loss: 0.2633 - val_accuracy: 0.9409 - val_loss: 0.1990\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9369 - loss: 0.2347 - val_accuracy: 0.9451 - val_loss: 0.1995\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9396 - loss: 0.1982 - val_accuracy: 0.9409 - val_loss: 0.1981\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9358 - loss: 0.1990 - val_accuracy: 0.9409 - val_loss: 0.1962\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9355 - loss: 0.2185 - val_accuracy: 0.9409 - val_loss: 0.1954\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9284 - loss: 0.2172 - val_accuracy: 0.9409 - val_loss: 0.1934\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9290 - loss: 0.2177 - val_accuracy: 0.9494 - val_loss: 0.1871\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9357 - loss: 0.1878 - val_accuracy: 0.9494 - val_loss: 0.1879\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9428 - loss: 0.1794 - val_accuracy: 0.9409 - val_loss: 0.1894\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9287 - loss: 0.2226 - val_accuracy: 0.9409 - val_loss: 0.1907\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9325 - loss: 0.1902 - val_accuracy: 0.9451 - val_loss: 0.1906\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9462 - loss: 0.1578 - val_accuracy: 0.9409 - val_loss: 0.1894\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9431 - loss: 0.1709 - val_accuracy: 0.9409 - val_loss: 0.1861\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9346 - loss: 0.1796 - val_accuracy: 0.9451 - val_loss: 0.1848\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9350 - loss: 0.1858 - val_accuracy: 0.9451 - val_loss: 0.1883\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9401 - loss: 0.1678 - val_accuracy: 0.9409 - val_loss: 0.1894\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9506 - loss: 0.1541 - val_accuracy: 0.9409 - val_loss: 0.1876\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9519 - loss: 0.1506 - val_accuracy: 0.9409 - val_loss: 0.1863\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9469 - loss: 0.1533 - val_accuracy: 0.9409 - val_loss: 0.1885\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9537 - loss: 0.1381 - val_accuracy: 0.9409 - val_loss: 0.1929\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9388 - loss: 0.1723 - val_accuracy: 0.9451 - val_loss: 0.1902\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9361 - loss: 0.1687 - val_accuracy: 0.9451 - val_loss: 0.1909\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9456 - loss: 0.1570 - val_accuracy: 0.9409 - val_loss: 0.1896\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9460 - loss: 0.1593 - val_accuracy: 0.9409 - val_loss: 0.1920\n",
      "Epoch 32/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9402 - loss: 0.1533 - val_accuracy: 0.9409 - val_loss: 0.1868\n",
      "Epoch 33/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9587 - loss: 0.1354 - val_accuracy: 0.9409 - val_loss: 0.1878\n",
      "Epoch 34/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9418 - loss: 0.1433 - val_accuracy: 0.9409 - val_loss: 0.1915\n",
      "Epoch 35/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9529 - loss: 0.1380 - val_accuracy: 0.9409 - val_loss: 0.1925\n",
      "Epoch 36/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9466 - loss: 0.1553 - val_accuracy: 0.9409 - val_loss: 0.1985\n",
      "Epoch 37/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9497 - loss: 0.1278 - val_accuracy: 0.9409 - val_loss: 0.1959\n",
      "Epoch 38/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9456 - loss: 0.1549 - val_accuracy: 0.9409 - val_loss: 0.1965\n",
      "Epoch 39/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9577 - loss: 0.1135 - val_accuracy: 0.9409 - val_loss: 0.1970\n",
      "Epoch 40/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9359 - loss: 0.1356 - val_accuracy: 0.9409 - val_loss: 0.2016\n",
      "Epoch 41/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9537 - loss: 0.1318 - val_accuracy: 0.9409 - val_loss: 0.2060\n",
      "Epoch 42/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9464 - loss: 0.1350 - val_accuracy: 0.9409 - val_loss: 0.2021\n",
      "Epoch 43/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9572 - loss: 0.1334 - val_accuracy: 0.9409 - val_loss: 0.1995\n",
      "Epoch 44/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9463 - loss: 0.1342 - val_accuracy: 0.9409 - val_loss: 0.2047\n",
      "Epoch 45/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9590 - loss: 0.1199 - val_accuracy: 0.9409 - val_loss: 0.2056\n",
      "Epoch 46/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9541 - loss: 0.1255 - val_accuracy: 0.9409 - val_loss: 0.2034\n",
      "Epoch 47/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9625 - loss: 0.1055 - val_accuracy: 0.9409 - val_loss: 0.2083\n",
      "Epoch 48/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9537 - loss: 0.1169 - val_accuracy: 0.9409 - val_loss: 0.2073\n",
      "Epoch 49/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9661 - loss: 0.1031 - val_accuracy: 0.9409 - val_loss: 0.2166\n",
      "Epoch 50/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9596 - loss: 0.0958 - val_accuracy: 0.9409 - val_loss: 0.2111\n",
      "Epoch 51/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9569 - loss: 0.1063 - val_accuracy: 0.9409 - val_loss: 0.2153\n",
      "Epoch 52/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9628 - loss: 0.1065 - val_accuracy: 0.9409 - val_loss: 0.2255\n",
      "Epoch 53/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9705 - loss: 0.0943 - val_accuracy: 0.9409 - val_loss: 0.2242\n",
      "Epoch 54/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9711 - loss: 0.0974 - val_accuracy: 0.9409 - val_loss: 0.2176\n",
      "Epoch 55/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9562 - loss: 0.1001 - val_accuracy: 0.9409 - val_loss: 0.2226\n",
      "Epoch 56/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9494 - loss: 0.1352 - val_accuracy: 0.9409 - val_loss: 0.2288\n",
      "Epoch 57/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9350 - loss: 0.1336 - val_accuracy: 0.9409 - val_loss: 0.2298\n",
      "Epoch 58/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9582 - loss: 0.1117 - val_accuracy: 0.9409 - val_loss: 0.2341\n",
      "Epoch 59/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9735 - loss: 0.0884 - val_accuracy: 0.9409 - val_loss: 0.2334\n",
      "Epoch 60/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9605 - loss: 0.0961 - val_accuracy: 0.9409 - val_loss: 0.2268\n",
      "Epoch 61/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9706 - loss: 0.0775 - val_accuracy: 0.9409 - val_loss: 0.2263\n",
      "Epoch 62/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9662 - loss: 0.0941 - val_accuracy: 0.9409 - val_loss: 0.2421\n",
      "Epoch 63/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9567 - loss: 0.1181 - val_accuracy: 0.9367 - val_loss: 0.2452\n",
      "Epoch 64/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9776 - loss: 0.0742 - val_accuracy: 0.9409 - val_loss: 0.2434\n",
      "Epoch 65/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9608 - loss: 0.0953 - val_accuracy: 0.9451 - val_loss: 0.2380\n",
      "Epoch 66/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9755 - loss: 0.0704 - val_accuracy: 0.9409 - val_loss: 0.2424\n",
      "Epoch 67/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9666 - loss: 0.0935 - val_accuracy: 0.9451 - val_loss: 0.2412\n",
      "Epoch 68/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9686 - loss: 0.0900 - val_accuracy: 0.9451 - val_loss: 0.2406\n",
      "Epoch 69/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9684 - loss: 0.0743 - val_accuracy: 0.9451 - val_loss: 0.2514\n",
      "Epoch 70/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9703 - loss: 0.0841 - val_accuracy: 0.9409 - val_loss: 0.2482\n",
      "Epoch 71/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.0872 - val_accuracy: 0.9494 - val_loss: 0.2531\n",
      "Epoch 72/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.0797 - val_accuracy: 0.9451 - val_loss: 0.2525\n",
      "Epoch 73/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9785 - loss: 0.0658 - val_accuracy: 0.9494 - val_loss: 0.2666\n",
      "Epoch 74/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9727 - loss: 0.0879 - val_accuracy: 0.9494 - val_loss: 0.2618\n",
      "Epoch 75/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.0817 - val_accuracy: 0.9494 - val_loss: 0.2616\n",
      "Epoch 76/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9639 - loss: 0.0932 - val_accuracy: 0.9451 - val_loss: 0.2635\n",
      "Epoch 77/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9785 - loss: 0.0667 - val_accuracy: 0.9494 - val_loss: 0.2821\n",
      "Epoch 78/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9560 - loss: 0.0965 - val_accuracy: 0.9494 - val_loss: 0.2805\n",
      "Epoch 79/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9707 - loss: 0.0932 - val_accuracy: 0.9451 - val_loss: 0.2733\n",
      "Epoch 80/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9755 - loss: 0.0752 - val_accuracy: 0.9451 - val_loss: 0.2651\n",
      "Epoch 81/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9649 - loss: 0.0921 - val_accuracy: 0.9494 - val_loss: 0.2794\n",
      "Epoch 82/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9707 - loss: 0.0697 - val_accuracy: 0.9451 - val_loss: 0.2778\n",
      "Epoch 83/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9691 - loss: 0.0866 - val_accuracy: 0.9451 - val_loss: 0.2852\n",
      "Epoch 84/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.0576 - val_accuracy: 0.9494 - val_loss: 0.2873\n",
      "Epoch 85/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9670 - loss: 0.0669 - val_accuracy: 0.9494 - val_loss: 0.2782\n",
      "Epoch 86/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9686 - loss: 0.0676 - val_accuracy: 0.9494 - val_loss: 0.2815\n",
      "Epoch 87/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.0756 - val_accuracy: 0.9494 - val_loss: 0.2826\n",
      "Epoch 88/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0667 - val_accuracy: 0.9451 - val_loss: 0.2978\n",
      "Epoch 89/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9779 - loss: 0.0578 - val_accuracy: 0.9494 - val_loss: 0.2946\n",
      "Epoch 90/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9619 - loss: 0.0860 - val_accuracy: 0.9494 - val_loss: 0.2930\n",
      "Epoch 91/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9759 - loss: 0.0700 - val_accuracy: 0.9494 - val_loss: 0.2913\n",
      "Epoch 92/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9788 - loss: 0.0605 - val_accuracy: 0.9494 - val_loss: 0.2992\n",
      "Epoch 93/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0558 - val_accuracy: 0.9494 - val_loss: 0.3101\n",
      "Epoch 94/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0587 - val_accuracy: 0.9494 - val_loss: 0.3110\n",
      "Epoch 95/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9705 - loss: 0.0810 - val_accuracy: 0.9494 - val_loss: 0.3253\n",
      "Epoch 96/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9725 - loss: 0.0704 - val_accuracy: 0.9494 - val_loss: 0.3242\n",
      "Epoch 97/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9694 - loss: 0.0747 - val_accuracy: 0.9451 - val_loss: 0.3286\n",
      "Epoch 98/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9671 - loss: 0.0808 - val_accuracy: 0.9494 - val_loss: 0.3311\n",
      "Epoch 99/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9692 - loss: 0.0887 - val_accuracy: 0.9451 - val_loss: 0.3280\n",
      "Epoch 100/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.0825 - val_accuracy: 0.9451 - val_loss: 0.3162\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9622 - loss: 0.2324 \n",
      "Test Loss: 0.33156222105026245, Test Accuracy: 0.9409449100494385\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터 준비\n",
    "# X와 y는 특성과 타겟 데이터입니다. 이에 맞게 데이터를 로드하고 전처리합니다.\n",
    "# 예시로는 적절한 데이터를 사용하여야 합니다.\n",
    "\n",
    "# 데이터 전처리\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_raw_x)  # 특성 스케일링\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df_raw_y,\n",
    "                                                    test_size=0.3, random_state=1234, stratify=df_raw_y )  # 훈련/검증 데이터 분할\n",
    "\n",
    "# 모델 구성\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # 입력 레이어\n",
    "    Dropout(0.5),  # 드롭아웃 레이어\n",
    "    Dense(64, activation='relu'),  # 은닉 레이어\n",
    "    Dropout(0.5),  # 드롭아웃 레이어\n",
    "    Dense(1, activation='sigmoid')  # 출력 레이어 (이진 분류이므로 시그모이드 활성화 함수 사용)\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',  # 이진 분류이므로 binary crossentropy 사용\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b545a24-22df-455b-8e23-c178a5b916be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Confusion Matrix:\n",
      "[[467   5]\n",
      " [ 25  11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       472\n",
      "         1.0       0.69      0.31      0.42        36\n",
      "\n",
      "    accuracy                           0.94       508\n",
      "   macro avg       0.82      0.65      0.70       508\n",
      "weighted avg       0.93      0.94      0.93       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "# 분류 보고서 출력\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0d0045a-36e2-4430-adc2-d8da8dc40500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "985c855f-2391-403f-ae1f-9f0f0665f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5816 - loss: 0.6815 - val_accuracy: 0.4955 - val_loss: 0.7316\n",
      "Epoch 2/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7257 - loss: 0.5561 - val_accuracy: 0.5295 - val_loss: 0.6738\n",
      "Epoch 3/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7354 - loss: 0.5101 - val_accuracy: 0.6432 - val_loss: 0.5499\n",
      "Epoch 4/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7588 - loss: 0.4633 - val_accuracy: 0.6750 - val_loss: 0.5073\n",
      "Epoch 5/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7775 - loss: 0.4270 - val_accuracy: 0.7432 - val_loss: 0.4560\n",
      "Epoch 6/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8059 - loss: 0.4010 - val_accuracy: 0.7886 - val_loss: 0.4130\n",
      "Epoch 7/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8506 - loss: 0.3409 - val_accuracy: 0.8341 - val_loss: 0.3956\n",
      "Epoch 8/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8378 - loss: 0.3422 - val_accuracy: 0.8568 - val_loss: 0.3482\n",
      "Epoch 9/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8623 - loss: 0.3084 - val_accuracy: 0.9295 - val_loss: 0.2798\n",
      "Epoch 10/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8664 - loss: 0.3001 - val_accuracy: 0.9364 - val_loss: 0.2510\n",
      "Epoch 11/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8655 - loss: 0.2880 - val_accuracy: 0.9295 - val_loss: 0.2746\n",
      "Epoch 12/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8971 - loss: 0.2684 - val_accuracy: 0.9409 - val_loss: 0.2251\n",
      "Epoch 13/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8893 - loss: 0.2532 - val_accuracy: 0.9500 - val_loss: 0.1992\n",
      "Epoch 14/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8922 - loss: 0.2565 - val_accuracy: 0.9591 - val_loss: 0.1832\n",
      "Epoch 15/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9112 - loss: 0.2157 - val_accuracy: 0.9545 - val_loss: 0.1987\n",
      "Epoch 16/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9205 - loss: 0.2248 - val_accuracy: 0.9750 - val_loss: 0.1435\n",
      "Epoch 17/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9164 - loss: 0.2138 - val_accuracy: 0.9818 - val_loss: 0.1418\n",
      "Epoch 18/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9309 - loss: 0.1954 - val_accuracy: 0.9841 - val_loss: 0.1362\n",
      "Epoch 19/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9327 - loss: 0.1974 - val_accuracy: 0.9909 - val_loss: 0.1117\n",
      "Epoch 20/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9437 - loss: 0.1642 - val_accuracy: 0.9864 - val_loss: 0.0994\n",
      "Epoch 21/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9355 - loss: 0.1755 - val_accuracy: 0.9886 - val_loss: 0.1078\n",
      "Epoch 22/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9413 - loss: 0.1856 - val_accuracy: 0.9909 - val_loss: 0.0934\n",
      "Epoch 23/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9261 - loss: 0.1734 - val_accuracy: 0.9886 - val_loss: 0.1116\n",
      "Epoch 24/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9539 - loss: 0.1559 - val_accuracy: 0.9932 - val_loss: 0.0799\n",
      "Epoch 25/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9445 - loss: 0.1464 - val_accuracy: 0.9977 - val_loss: 0.0826\n",
      "Epoch 26/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9522 - loss: 0.1216 - val_accuracy: 0.9932 - val_loss: 0.0739\n",
      "Epoch 27/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9499 - loss: 0.1320 - val_accuracy: 0.9955 - val_loss: 0.0868\n",
      "Epoch 28/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9487 - loss: 0.1496 - val_accuracy: 0.9955 - val_loss: 0.0674\n",
      "Epoch 29/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9564 - loss: 0.1309 - val_accuracy: 0.9977 - val_loss: 0.0552\n",
      "Epoch 30/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9617 - loss: 0.1032 - val_accuracy: 0.9955 - val_loss: 0.0745\n",
      "Epoch 31/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9595 - loss: 0.1249 - val_accuracy: 0.9886 - val_loss: 0.0781\n",
      "Epoch 32/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9633 - loss: 0.1236 - val_accuracy: 0.9932 - val_loss: 0.0701\n",
      "Epoch 33/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.1191 - val_accuracy: 0.9886 - val_loss: 0.0733\n",
      "Epoch 34/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9609 - loss: 0.1047 - val_accuracy: 0.9886 - val_loss: 0.0744\n",
      "Epoch 35/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9659 - loss: 0.0993 - val_accuracy: 0.9955 - val_loss: 0.0449\n",
      "Epoch 36/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9662 - loss: 0.0988 - val_accuracy: 0.9955 - val_loss: 0.0521\n",
      "Epoch 37/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9600 - loss: 0.1073 - val_accuracy: 0.9909 - val_loss: 0.0440\n",
      "Epoch 38/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.0926 - val_accuracy: 0.9909 - val_loss: 0.0606\n",
      "Epoch 39/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9675 - loss: 0.0980 - val_accuracy: 0.9955 - val_loss: 0.0514\n",
      "Epoch 40/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9725 - loss: 0.0814 - val_accuracy: 0.9909 - val_loss: 0.0507\n",
      "Epoch 41/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9571 - loss: 0.1119 - val_accuracy: 0.9932 - val_loss: 0.0481\n",
      "Epoch 42/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9679 - loss: 0.0966 - val_accuracy: 0.9955 - val_loss: 0.0416\n",
      "Epoch 43/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9706 - loss: 0.0957 - val_accuracy: 0.9932 - val_loss: 0.0575\n",
      "Epoch 44/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9697 - loss: 0.0920 - val_accuracy: 0.9955 - val_loss: 0.0459\n",
      "Epoch 45/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9741 - loss: 0.0786 - val_accuracy: 1.0000 - val_loss: 0.0345\n",
      "Epoch 46/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.0797 - val_accuracy: 0.9977 - val_loss: 0.0376\n",
      "Epoch 47/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9680 - loss: 0.0851 - val_accuracy: 0.9977 - val_loss: 0.0486\n",
      "Epoch 48/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9695 - loss: 0.0873 - val_accuracy: 1.0000 - val_loss: 0.0278\n",
      "Epoch 49/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.0741 - val_accuracy: 0.9955 - val_loss: 0.0496\n",
      "Epoch 50/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9654 - loss: 0.0889 - val_accuracy: 0.9977 - val_loss: 0.0434\n",
      "Epoch 51/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9620 - loss: 0.0982 - val_accuracy: 0.9932 - val_loss: 0.0440\n",
      "Epoch 52/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9736 - loss: 0.0717 - val_accuracy: 1.0000 - val_loss: 0.0387\n",
      "Epoch 53/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9620 - loss: 0.0941 - val_accuracy: 1.0000 - val_loss: 0.0287\n",
      "Epoch 54/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9724 - loss: 0.0680 - val_accuracy: 1.0000 - val_loss: 0.0269\n",
      "Epoch 55/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9768 - loss: 0.0643 - val_accuracy: 0.9955 - val_loss: 0.0402\n",
      "Epoch 56/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9754 - loss: 0.0603 - val_accuracy: 1.0000 - val_loss: 0.0295\n",
      "Epoch 57/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.0583 - val_accuracy: 1.0000 - val_loss: 0.0243\n",
      "Epoch 58/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9758 - loss: 0.0588 - val_accuracy: 1.0000 - val_loss: 0.0300\n",
      "Epoch 59/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9720 - loss: 0.0729 - val_accuracy: 1.0000 - val_loss: 0.0216\n",
      "Epoch 60/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.0633 - val_accuracy: 1.0000 - val_loss: 0.0277\n",
      "Epoch 61/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 0.0554 - val_accuracy: 1.0000 - val_loss: 0.0231\n",
      "Epoch 62/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9801 - loss: 0.0662 - val_accuracy: 1.0000 - val_loss: 0.0198\n",
      "Epoch 63/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9745 - loss: 0.0653 - val_accuracy: 1.0000 - val_loss: 0.0166\n",
      "Epoch 64/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9731 - loss: 0.0651 - val_accuracy: 1.0000 - val_loss: 0.0208\n",
      "Epoch 65/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0739 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
      "Epoch 66/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0637 - val_accuracy: 1.0000 - val_loss: 0.0267\n",
      "Epoch 67/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9850 - loss: 0.0545 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
      "Epoch 68/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 0.0242\n",
      "Epoch 69/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9808 - loss: 0.0634 - val_accuracy: 1.0000 - val_loss: 0.0155\n",
      "Epoch 70/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9850 - loss: 0.0427 - val_accuracy: 0.9977 - val_loss: 0.0236\n",
      "Epoch 71/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0553 - val_accuracy: 1.0000 - val_loss: 0.0160\n",
      "Epoch 72/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0406 - val_accuracy: 0.9977 - val_loss: 0.0265\n",
      "Epoch 73/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9809 - loss: 0.0509 - val_accuracy: 1.0000 - val_loss: 0.0182\n",
      "Epoch 74/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0517 - val_accuracy: 1.0000 - val_loss: 0.0121\n",
      "Epoch 75/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9774 - loss: 0.0535 - val_accuracy: 1.0000 - val_loss: 0.0151\n",
      "Epoch 76/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9835 - loss: 0.0500 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
      "Epoch 77/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9821 - loss: 0.0558 - val_accuracy: 1.0000 - val_loss: 0.0158\n",
      "Epoch 78/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.0441 - val_accuracy: 1.0000 - val_loss: 0.0240\n",
      "Epoch 79/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0402 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
      "Epoch 80/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9794 - loss: 0.0602 - val_accuracy: 1.0000 - val_loss: 0.0165\n",
      "Epoch 81/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0428 - val_accuracy: 1.0000 - val_loss: 0.0158\n",
      "Epoch 82/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 0.0539 - val_accuracy: 1.0000 - val_loss: 0.0156\n",
      "Epoch 83/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9865 - loss: 0.0407 - val_accuracy: 1.0000 - val_loss: 0.0105\n",
      "Epoch 84/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9801 - loss: 0.0538 - val_accuracy: 1.0000 - val_loss: 0.0109\n",
      "Epoch 85/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0412 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
      "Epoch 86/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9858 - loss: 0.0519 - val_accuracy: 1.0000 - val_loss: 0.0125\n",
      "Epoch 87/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.0460 - val_accuracy: 1.0000 - val_loss: 0.0081\n",
      "Epoch 88/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0328 - val_accuracy: 1.0000 - val_loss: 0.0151\n",
      "Epoch 89/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9865 - loss: 0.0394 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
      "Epoch 90/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.0388 - val_accuracy: 1.0000 - val_loss: 0.0188\n",
      "Epoch 91/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9767 - loss: 0.0563 - val_accuracy: 1.0000 - val_loss: 0.0153\n",
      "Epoch 92/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9849 - loss: 0.0514 - val_accuracy: 0.9977 - val_loss: 0.0214\n",
      "Epoch 93/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9872 - loss: 0.0480 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
      "Epoch 94/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 0.0507 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
      "Epoch 95/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.0444 - val_accuracy: 1.0000 - val_loss: 0.0105\n",
      "Epoch 96/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9891 - loss: 0.0357 - val_accuracy: 1.0000 - val_loss: 0.0150\n",
      "Epoch 97/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0357 - val_accuracy: 0.9977 - val_loss: 0.0187\n",
      "Epoch 98/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0381 - val_accuracy: 1.0000 - val_loss: 0.0148\n",
      "Epoch 99/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0324 - val_accuracy: 1.0000 - val_loss: 0.0089\n",
      "Epoch 100/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9863 - loss: 0.0391 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 101/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0462 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
      "Epoch 102/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0430 - val_accuracy: 1.0000 - val_loss: 0.0094\n",
      "Epoch 103/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0316 - val_accuracy: 1.0000 - val_loss: 0.0105\n",
      "Epoch 104/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 0.0110\n",
      "Epoch 105/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0306 - val_accuracy: 1.0000 - val_loss: 0.0112\n",
      "Epoch 106/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9872 - loss: 0.0395 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
      "Epoch 107/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0371 - val_accuracy: 1.0000 - val_loss: 0.0124\n",
      "Epoch 108/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0300 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 109/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
      "Epoch 110/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0443 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "Epoch 111/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9922 - loss: 0.0320 - val_accuracy: 1.0000 - val_loss: 0.0120\n",
      "Epoch 112/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0362 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
      "Epoch 113/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9848 - loss: 0.0378 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
      "Epoch 114/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.0372 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
      "Epoch 115/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0277 - val_accuracy: 1.0000 - val_loss: 0.0089\n",
      "Epoch 116/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9856 - loss: 0.0442 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
      "Epoch 117/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0234 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 118/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
      "Epoch 119/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0305 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
      "Epoch 120/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.0258 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
      "Epoch 121/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0070\n",
      "Epoch 122/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0307 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 123/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 124/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0254 - val_accuracy: 1.0000 - val_loss: 0.0071\n",
      "Epoch 125/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.0535 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
      "Epoch 126/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9891 - loss: 0.0351 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 127/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 128/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0391 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
      "Epoch 129/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0269 - val_accuracy: 1.0000 - val_loss: 0.0086\n",
      "Epoch 130/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0302 - val_accuracy: 1.0000 - val_loss: 0.0091\n",
      "Epoch 131/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.0276 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 132/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9917 - loss: 0.0296 - val_accuracy: 1.0000 - val_loss: 0.0120\n",
      "Epoch 133/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.0346 - val_accuracy: 1.0000 - val_loss: 0.0143\n",
      "Epoch 134/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0355 - val_accuracy: 1.0000 - val_loss: 0.0110\n",
      "Epoch 135/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0259 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
      "Epoch 136/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9897 - loss: 0.0298 - val_accuracy: 1.0000 - val_loss: 0.0086\n",
      "Epoch 137/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0373 - val_accuracy: 1.0000 - val_loss: 0.0082\n",
      "Epoch 138/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
      "Epoch 139/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 0.0093\n",
      "Epoch 140/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 141/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 142/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
      "Epoch 143/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
      "Epoch 144/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0233 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 145/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 146/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.0296 - val_accuracy: 0.9977 - val_loss: 0.0103\n",
      "Epoch 147/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9883 - loss: 0.0463 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
      "Epoch 148/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0294 - val_accuracy: 0.9977 - val_loss: 0.0095\n",
      "Epoch 149/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9946 - loss: 0.0213 - val_accuracy: 1.0000 - val_loss: 0.0094\n",
      "Epoch 150/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0266 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 151/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0229 - val_accuracy: 1.0000 - val_loss: 0.0060\n",
      "Epoch 152/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0222 - val_accuracy: 1.0000 - val_loss: 0.0063\n",
      "Epoch 153/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0212 - val_accuracy: 1.0000 - val_loss: 0.0089\n",
      "Epoch 154/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0383 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 155/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9906 - loss: 0.0327 - val_accuracy: 1.0000 - val_loss: 0.0050\n",
      "Epoch 156/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0223 - val_accuracy: 1.0000 - val_loss: 0.0050\n",
      "Epoch 157/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9927 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 158/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 159/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0186 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 160/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0235 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 161/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 162/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
      "Epoch 163/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 164/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0216 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 165/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 166/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0173 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
      "Epoch 167/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
      "Epoch 168/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0083\n",
      "Epoch 169/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0332 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "Epoch 170/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9901 - loss: 0.0317 - val_accuracy: 1.0000 - val_loss: 0.0060\n",
      "Epoch 171/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0233 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 172/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0241 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 173/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 174/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0257 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 175/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
      "Epoch 176/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0277 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 177/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
      "Epoch 178/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9878 - loss: 0.0491 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
      "Epoch 179/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 180/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0162 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 181/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0285 - val_accuracy: 1.0000 - val_loss: 0.0075\n",
      "Epoch 182/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0191 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
      "Epoch 183/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
      "Epoch 184/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 185/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
      "Epoch 186/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0237 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
      "Epoch 187/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 188/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0193 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 189/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9956 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
      "Epoch 190/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.0370 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
      "Epoch 191/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.0186 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 192/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 193/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
      "Epoch 194/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 195/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9919 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
      "Epoch 196/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0157 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 197/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 198/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0231 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 199/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
      "Epoch 200/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 201/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 202/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0176 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 203/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 204/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 205/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9956 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
      "Epoch 206/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 207/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
      "Epoch 208/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 209/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0124 - val_accuracy: 0.9977 - val_loss: 0.0056\n",
      "Epoch 210/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 211/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 212/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 213/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 214/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 215/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 216/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 217/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 218/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 219/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0176 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 220/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 221/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0171 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 222/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0283 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 223/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 224/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 225/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 226/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 227/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0235 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 228/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0153 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 229/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 230/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0207 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 231/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 232/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 233/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0228 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 234/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 235/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0336 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 236/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0180 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 237/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
      "Epoch 238/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9893 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 239/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 240/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 241/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 242/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 243/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 244/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 245/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9944 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 246/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
      "Epoch 247/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 248/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.0312 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 249/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 250/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0210 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 251/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 252/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 253/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 254/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 255/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 256/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0186 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 257/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0146 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 258/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
      "Epoch 259/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
      "Epoch 260/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 261/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0328 - val_accuracy: 0.9977 - val_loss: 0.0066\n",
      "Epoch 262/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 263/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 264/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 265/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 266/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0162 - val_accuracy: 0.9977 - val_loss: 0.0068\n",
      "Epoch 267/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 268/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0153 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 269/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0157 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 270/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0053\n",
      "Epoch 271/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9960 - loss: 0.0125 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 272/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 273/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9960 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 274/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 275/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 276/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 277/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 278/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 279/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 280/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 281/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 282/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 283/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0152 - val_accuracy: 0.9977 - val_loss: 0.0043\n",
      "Epoch 284/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 285/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 286/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 287/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 288/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 289/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 290/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 291/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0060\n",
      "Epoch 292/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 293/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 294/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 9.2950e-04\n",
      "Epoch 295/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0163 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 296/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 297/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 298/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 299/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 300/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0177 - val_accuracy: 0.9977 - val_loss: 0.0062\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 1.1510     \n",
      "Test Loss: 1.5714613199234009, Test Accuracy: 0.9350393414497375\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # 입력 레이어\n",
    "    Dropout(0.5),  # 드롭아웃 레이어\n",
    "    Dense(64, activation='relu'),  # 은닉 레이어\n",
    "    Dropout(0.5),  # 드롭아웃 레이어\n",
    "    Dense(1, activation='sigmoid')  # 출력 레이어 (이진 분류이므로 시그모이드 활성화 함수 사용)\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',  # 이진 분류이므로 binary crossentropy 사용\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_resampled, y_resampled, epochs=300, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e67e18a4-4bdc-4b9f-8266-30daf57386c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Confusion Matrix:\n",
      "[[466   6]\n",
      " [ 27   9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       472\n",
      "         1.0       0.60      0.25      0.35        36\n",
      "\n",
      "    accuracy                           0.94       508\n",
      "   macro avg       0.77      0.62      0.66       508\n",
      "weighted avg       0.92      0.94      0.92       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "# 분류 보고서 출력\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b2156-d2c3-4aea-af3e-578b34a83a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
