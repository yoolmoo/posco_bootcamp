{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f31291a-7cd7-4526-a963-7080de7236ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ec6b9c-6806-4e9d-b00e-40c6d5446264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3790be5-7417-4254-9be6-99b07a380265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"01 Oxidation.csv\")\n",
    "df2 = pd.read_csv(\"02 Photo_softbake.csv\")\n",
    "df3 = pd.read_csv(\"03 Photo_lithograpy.csv\")\n",
    "df4 = pd.read_csv(\"04 Etching.csv\")\n",
    "df5 = pd.read_csv(\"05 Ion_Implantation.csv\")\n",
    "df6 = pd.read_csv(\"06 Inspect.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc8bad3-18cb-43f1-bd1c-7bbfc7163d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])\n",
    "df = pd.merge(df, df3, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])\n",
    "df = pd.merge(df, df4, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])\n",
    "df = pd.merge(df, df5, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])\n",
    "df = pd.merge(df, df6, on=['No_Die','Lot_Num', 'Wafer_Num','Datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "587f2b7b-5130-46f8-b82e-4d22185bb662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=\"Thin F2\", inplace=True) # 다른 변수들과의 연관성을 찾지못함, 한 행에 여러 열들 결측값 가짐\n",
    "# pd.set_option('display.max_row', 200)\n",
    "# pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1bfdab-68c3-446d-9b13-e85be3c070e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ox_Chamber'] = df['Ox_Chamber'].astype('str')\n",
    "df['photo_soft_Chamber'] = df['photo_soft_Chamber'].astype('str')\n",
    "df['lithography_Chamber'] = df['lithography_Chamber'].astype('str')\n",
    "df['Etching_Chamber'] = df['Etching_Chamber'].astype('str')\n",
    "df['Chamber_Num'] = df['Chamber_Num'].astype('str')\n",
    "df['path'] = df['Ox_Chamber']+df['photo_soft_Chamber']+df['lithography_Chamber']+df['Etching_Chamber']+df['Chamber_Num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473e2781-842c-490c-ab04-86d823e303ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(df[df['Oxid_time']<0].index, inplace=True) # 산화시간이 음수\n",
    "df.drop(df[df['Target']==0].index, inplace=True) # target 값이 0\n",
    "df.drop(columns = [\"Wafer_map\",\"Error_message\"],inplace=True) # 웨이퍼맵, 에러메시지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1335a37d-5e7f-4308-b788-e3394e9a72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 데이터 datetime 유형으로 변환\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'], format='%d-%m-%Y')\n",
    "\n",
    "# 195이상 = 불량(1), 195미만 = 양품(0)\n",
    "df.loc[df['Target'] >= 195, '불량_195이상'] =1\n",
    "df.loc[df['Target'] < 195, '불량_195이상'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db7cfb0-e884-47a0-b1e2-b338eb40b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Thin F4']<0, 'Thin F4']=df['Thin F4'].median()\n",
    "df.loc[df['Flux90s']<0, 'Flux90s']=df['Flux90s'].median()\n",
    "df.loc[df['Flux160s']<0, 'Flux160s']=df['Flux160s'].median()\n",
    "df.loc[df['Flux160s']<5, 'Flux160s']=df['Flux160s'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acd283d7-4f43-4240-a57b-b403e041b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Thin F1'].fillna(df['Thin F1'].median(), inplace=True)\n",
    "df['Thin F3'].fillna(df['Thin F3'].median(), inplace=True)\n",
    "df['Flux60s'].fillna(df['Flux90s'].median(), inplace=True)\n",
    "df['Flux90s'].fillna(df['Flux90s'].median(), inplace=True)\n",
    "df['Flux480s'].fillna(df['Flux90s'].median(), inplace=True)\n",
    "df['Flux840s'].fillna(df['Flux90s'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4b6f3-d202-400e-9d08-81a9885dfa06",
   "metadata": {},
   "source": [
    "### 불필요한 열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64a1766d-1b14-42bc-b817-57fe8c553a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 열 제거 \n",
    "# df.drop(columns=[\"No_Die\", \"Lot_Num\", \"Wafer_Num\"], inplace=True)\n",
    "df.drop(columns=['Vapor','process','Wavelength'])\n",
    "df.loc[df['Flux840s'] == 8.137500e+16, 'Flux840s'] = df['Flux840s'].mode()[0]\n",
    "df.loc[df['Flux480s'] == 8.137500e+16, 'Flux480s'] = df['Flux480s'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edecc600-f595-458e-b623-d16f3670e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['Temp_OXid','ppm','Pressure','type','Oxid_time',\n",
    "        'N2_HMDS', 'pressure_HMDS', 'temp_HMDS', 'temp_HMDS_bake',\n",
    "       'time_HMDS_bake', 'spin1', 'spin2', 'spin3', 'photoresist_bake',\n",
    "       'temp_softbake', 'time_softbake', 'UV_type', 'Energy_Exposure',       \n",
    "        'Temp_Etching', 'Source_Power',\n",
    "       'input_Energy', 'Temp_implantation', 'Furance_Temp', 'RTA_Temp',\n",
    "       '불량_195이상', 'path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32c09858-5c1b-46ad-b4f5-43fe5e7ba974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 구성:Series, DataFrame\n",
    "import pandas as pd\n",
    "# 데이터 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 데이터 분할:train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 분류 Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# 최적 모델, 파라미터 탐색\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 분류모델 평가 함수\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "897b976d-7fcb-4a26-a444-276af007c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df_raw_x = df_new.drop(\"불량_195이상\", axis = 1)\n",
    "df_raw_y = df_new[\"불량_195이상\"] \n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "numeric_columns = df_raw_x.select_dtypes(include=['number']).columns\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_raw_x[numeric_columns] = scaler.fit_transform(df_raw_x[numeric_columns])\n",
    "\n",
    "df_raw_x = pd.get_dummies(df_raw_x, columns=df_raw_x.select_dtypes(include=['object']).columns)\n",
    "df_raw_x = df_raw_x.astype({column: int for column in df_raw_x.select_dtypes(include=['bool']).columns})\n",
    "\n",
    "df_train_x, df_test_x, df_train_y, df_test_y = train_test_split(\n",
    "    df_raw_x, df_raw_y, test_size = 0.3, random_state = 1234, stratify=df_raw_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84cc8d3f-6667-4b4a-a53f-ca495d33a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Confusion matrix: \n",
      "[[470   2]\n",
      " [ 25  11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.949     0.996     0.972       472\n",
      "         1.0      0.846     0.306     0.449        36\n",
      "\n",
      "    accuracy                          0.947       508\n",
      "   macro avg      0.898     0.651     0.711       508\n",
      "weighted avg      0.942     0.947     0.935       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 그래디언트 부스팅 모델 생성: GradientBoostingClassifier\n",
    "gb_uncust = GradientBoostingClassifier(random_state=1234)\n",
    "gb_uncust.fit(df_train_x, df_train_y)\n",
    "y_pred = gb_uncust.predict(df_test_x)\n",
    "\n",
    "print(\"Test Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "print(classification_report(df_test_y, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "080e4650-b3cb-4b1f-850d-c842ce5f7995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator model: \n",
      "GradientBoostingClassifier(learning_rate=0.7, max_depth=9, min_samples_leaf=26,\n",
      "                           n_estimators=216, random_state=1234)\n",
      "\n",
      "best parameter: \n",
      "{'learning_rate': 0.7, 'max_depth': 9, 'min_samples_leaf': 26, 'n_estimators': 216}\n",
      "\n",
      "best score: \n",
      "0.965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "estimator = GradientBoostingClassifier( random_state=1234)\n",
    "# 구하고자 하는 parameter와 범위\n",
    "param_dist = {\n",
    "    \"learning_rate\": [0.1, 0.3, 0.5, 0.7, 1],\n",
    "    \"max_depth\": sp_randint(3, 13),\n",
    "    \"min_samples_leaf\": sp_randint(5, 30),\n",
    "    'n_estimators': sp_randint(100, 300)\n",
    "}\n",
    "\n",
    "# Randomized Search 객체 생성\n",
    "random_search_gb = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=10, scoring=\"accuracy\", n_jobs=-1, random_state=1234)\n",
    "\n",
    "# Randomized Search 수행\n",
    "random_search_gb.fit(df_train_x, df_train_y)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"best estimator model: \\n{}\".format(random_search_gb.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(random_search_gb.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(random_search_gb.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b38212-8651-4477-af92-af4cece2ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.000\n",
      "Test Accuracy: 0.969\n",
      "\n",
      "Test Confusion matrix: \n",
      "[[466   6]\n",
      " [ 10  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.979     0.987     0.983       472\n",
      "         1.0      0.812     0.722     0.765        36\n",
      "\n",
      "    accuracy                          0.969       508\n",
      "   macro avg      0.896     0.855     0.874       508\n",
      "weighted avg      0.967     0.969     0.968       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_uncust=GradientBoostingClassifier(learning_rate=0.7, max_depth=9, min_samples_leaf=26,\n",
    "                           n_estimators=216, random_state=1234)\n",
    "gb_uncust.fit(df_train_x, df_train_y)\n",
    "y_pred = gb_uncust.predict(df_test_x)\n",
    "\n",
    "print(\"Train Accuracy: {:.3f}\".format(gb_uncust.score(df_train_x, df_train_y)))\n",
    "print(\"Test Accuracy: {:.3f}\\n\".format(gb_uncust.score(df_test_x, df_test_y)))\n",
    "print(\"Test Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "print(classification_report(df_test_y, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb1ae9-eb39-4ede-805d-f243bac31ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_blank = ['Pressure', 'Temp_OXid', 'temp_softbake', 'photoresist_bake', \n",
    "                    'Temp_Etching', 'Temp_implantation', 'spin1', 'spin2', 'Source_Power',\n",
    "                    'temp_HMDS_bake', 'ppm', 'RTA_Temp']\n",
    "\n",
    "# 대체할 값의 범위 설정\n",
    "value_ranges = {\n",
    "    'Pressure': (0.18, 0.192),\n",
    "    'Temp_OXid': (1294.58, 1348.47),\n",
    "    'temp_softbake': (95.28, 96.65),\n",
    "    'photoresist_bake': (5.14, 5.24),\n",
    "    'Temp_Etching': (68.15, 68.92),\n",
    "    'Temp_implantation': (97.74, 100.25),\n",
    "    'spin1': (492.2, 494),\n",
    "    'spin2': (5172.1, 5194.13),\n",
    "    'Source_Power': (49.34, 49.98),\n",
    "    'temp_HMDS_bake': (205.3, 209.5),\n",
    "    'ppm': (45.89, 49.91),\n",
    "    'RTA_Temp': (148, 149)\n",
    "}\n",
    "\n",
    "# 테스트 데이터프레임 복사\n",
    "df_test_x_modified = df_raw_x.copy()\n",
    "\n",
    "# 선택된 열들의 값을 NaN으로 설정\n",
    "for column in columns_to_blank:\n",
    "    df_test_x_modified[column] = np.nan\n",
    "\n",
    "# 나머지 열들의 값들을 설정된 범위 내에서 무작위로 생성하여 대체\n",
    "for column in df_test_x_modified.columns:\n",
    "    if column in columns_to_blank:\n",
    "        min_val, max_val = value_ranges[column]\n",
    "        random_values = np.random.rand(len(df_test_x_modified))  # [0, 1) 사이의 균일한 확률 분포에서 값 생성\n",
    "        scaled_values = random_values * (max_val - min_val) + min_val  # 원하는 범위에 맞게 조정\n",
    "        df_test_x_modified[column] = scaled_values\n",
    "\n",
    "# 결과 확인\n",
    "df_test_x_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3abc6-14e6-4cfa-801b-c6099e233f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_uncust = GradientBoostingClassifier(learning_rate=0.3, max_depth=9, min_samples_leaf=30,\n",
    "                                       n_estimators=200, random_state=1234)\n",
    "gb_uncust.fit(df_train_x, df_train_y)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 확률\n",
    "y_proba = gb_uncust.predict_proba(df_test_x)\n",
    "y_pred = (y_proba[:, 1] > 0.2).astype(int)\n",
    "# 확률 출력\n",
    "print(classification_report(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56daba91-d42d-427a-8b73-748b82af50af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 예측 확률\n",
    "y_proba = gb_uncust.predict_proba(df_test_x_modified)\n",
    "y_pred = (y_proba[:, 1] > 0.2).astype(int)\n",
    "# 확률 출력\n",
    "\n",
    "np.sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443a12d-5133-4c3f-9bcc-e1a111d40f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_feature_name = df_train_x.columns\n",
    "\n",
    "df_importance = pd.DataFrame()\n",
    "df_importance [\"Feature\"] = v_feature_name\n",
    "df_importance [\"Importance\"] = gb_uncust.feature_importances_\n",
    "df_importance .sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_importance .round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9017416-31ea-4f41-bcfb-c4b594c32554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame()\n",
    "df_importance[\"Feature\"] = v_feature_name\n",
    "df_importance[\"Importance\"] = gb_uncust.feature_importances_\n",
    "\n",
    "# df_feature_importance의 테이블을 중요도별로 정렬\n",
    "df_importance.sort_values(\"Importance\", ascending=False, inplace = True)\n",
    "df_importance.sort_values(\"Importance\", ascending=True, inplace = True)\n",
    "coordinates = range(len(df_importance))\n",
    "top_10_importance = df_importance.nlargest(10, \"Importance\")\n",
    "\n",
    "# 시각화\n",
    "coordinates = range(len(top_10_importance))\n",
    "plt.barh(y=coordinates[::-1], width=top_10_importance[\"Importance\"])\n",
    "plt.yticks(coordinates[::-1], top_10_importance[\"Feature\"], fontsize=10)\n",
    "plt.xlabel(\"변수 중요도\")\n",
    "plt.ylabel(\"변수\")\n",
    "plt.title(\"상위 10개 변수 중요도\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a219556c-9150-403a-b776-ecd9defe825f",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28f5d0b7-2255-48f5-9151-dd187a5b5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "585b41b3-22dd-4095-ae1f-486f14f83bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96       472\n",
      "         1.0       0.47      0.61      0.53        36\n",
      "\n",
      "    accuracy                           0.92       508\n",
      "   macro avg       0.72      0.78      0.74       508\n",
      "weighted avg       0.93      0.92      0.93       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(df_train_x, df_train_y)\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = gb_clf.predict(df_test_x)\n",
    "print(classification_report(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b158638-9804-4dad-a1dd-688d8c508fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator model: \n",
      "GradientBoostingClassifier(learning_rate=0.5, max_depth=9, min_samples_leaf=8,\n",
      "                           n_estimators=239, random_state=1234)\n",
      "\n",
      "best parameter: \n",
      "{'learning_rate': 0.5, 'max_depth': 9, 'min_samples_leaf': 8, 'n_estimators': 239}\n",
      "\n",
      "best score: \n",
      "0.989\n"
     ]
    }
   ],
   "source": [
    "estimator = GradientBoostingClassifier( random_state=1234)\n",
    "# 구하고자 하는 parameter와 범위\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "estimator = GradientBoostingClassifier( random_state=1234)\n",
    "# 구하고자 하는 parameter와 범위\n",
    "param_dist = {\n",
    "    \"learning_rate\": [0.1, 0.3, 0.5, 0.7, 1],\n",
    "    \"max_depth\": sp_randint(3, 13),\n",
    "    \"min_samples_leaf\": sp_randint(5, 30),\n",
    "    'n_estimators': sp_randint(100, 300)\n",
    "}\n",
    "\n",
    "# Randomized Search 객체 생성\n",
    "random_search_gb = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=10,\n",
    "                                      scoring=\"accuracy\", n_jobs=-1, random_state=1234)\n",
    "\n",
    "# Randomized Search 수행\n",
    "random_search_gb.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"best estimator model: \\n{}\".format(random_search_gb.best_estimator_))\n",
    "print(\"\\nbest parameter: \\n{}\".format(random_search_gb.best_params_))\n",
    "print(\"\\nbest score: \\n{}\".format(random_search_gb.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dacf7ce-45a4-421f-b57e-578b8711cde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[468   4]\n",
      " [ 11  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98       472\n",
      "         1.0       0.86      0.69      0.77        36\n",
      "\n",
      "    accuracy                           0.97       508\n",
      "   macro avg       0.92      0.84      0.88       508\n",
      "weighted avg       0.97      0.97      0.97       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_grad= GradientBoostingClassifier(learning_rate=0.5, max_depth=9, min_samples_leaf=8,\n",
    "                           n_estimators=239, random_state=1234)\n",
    "best_grad.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = best_grad.predict(df_test_x)\n",
    "# y_proba = best_grad.predict_proba(df_test_x)\n",
    "# y_pred = (y_proba[:, 1] > 0.75).astype(int)\n",
    "\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(df_test_y, y_pred)))\n",
    "print(classification_report(df_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2327ff-e48c-4242-b28a-2534f415423e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
